{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Candidate Project Selection in CPDP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEJQfBIEIHSU",
        "outputId": "c7603900-9a07-4e18-f537-49fc2083d664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#importing google drive to load and store data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "0ppmU3XbO1mj"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import sklearn\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
        "from sklearn.metrics import roc_curve, auc, f1_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "#models\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8C9OCRplbaE",
        "outputId": "1659c589-4661-4bc6-fbf4-54f9f0049d4f"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "FXNb4GX9Ln8i"
      },
      "outputs": [],
      "source": [
        "ant = \"/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/ant 1.7.xlsx\"\n",
        "camel = '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/camel 1.6.xlsx'\n",
        "ivy = '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/ivy 2.0.xlsx'\n",
        "jedit = '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/jedit 4.3.xlsx'\n",
        "log4j= '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/log4 j1.2.xlsx'\n",
        "lucene = '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/lucene 2.4.xlsx'\n",
        "pbeans = '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/pbeans 2.xlsx'\n",
        "poi = '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/poi 3.xlsx'\n",
        "prop = '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/prop 85.xlsx'\n",
        "synapse = '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/synapse 1.2.xlsx'\n",
        "velocity = '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/velocity 1.6.xlsx'\n",
        "xalan = '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/xalan 2.7.xlsx'\n",
        "xer = '/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/xer 1..4.xlsx'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "vFsAGj6kMQh1"
      },
      "outputs": [],
      "source": [
        "list_of_projects = [ant, camel, ivy, jedit, log4j, lucene, pbeans, poi, prop,synapse,velocity, xalan, xer]      # directory to all projects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SouUGPYsdtGx",
        "outputId": "a9cfd3fd-079f-44aa-85bd-edcc92a6d541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/ant 1.7.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/camel 1.6.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/ivy 2.0.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/jedit 4.3.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/log4 j1.2.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/lucene 2.4.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/pbeans 2.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/poi 3.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/prop 85.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/synapse 1.2.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/velocity 1.6.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/xalan 2.7.xlsx\n",
            "/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/xer 1..4.xlsx\n"
          ]
        }
      ],
      "source": [
        "for  datasetSource in list_of_projects:\n",
        "        print(datasetSource)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generating metafeature vector\n",
        "df= pd.read_excel(ant)"
      ],
      "metadata": {
        "id": "YwKxvyPc_R4w"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "H4dkan1ZBO-X",
        "outputId": "2442b356-d1cb-4e5e-bff3-89d82e8848aa"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            version          wmc          dit          noc          cbo  \\\n",
              "count  1.066000e+03  1066.000000  1066.000000  1066.000000  1066.000000   \n",
              "mean   1.700000e+00     8.994371     2.331144     0.565666     8.756098   \n",
              "std    2.221488e-16    10.674262     1.320871     4.051998    22.469313   \n",
              "min    1.700000e+00     0.000000     1.000000     0.000000     0.000000   \n",
              "25%    1.700000e+00     3.000000     1.000000     0.000000     3.000000   \n",
              "50%    1.700000e+00     5.000000     2.000000     0.000000     5.000000   \n",
              "75%    1.700000e+00    11.000000     3.000000     0.000000     9.000000   \n",
              "max    1.700000e+00   120.000000     7.000000   102.000000   499.000000   \n",
              "\n",
              "               rfc         lcom           ca           ce          npm  ...  \\\n",
              "count  1066.000000  1066.000000  1066.000000  1066.000000  1066.000000  ...   \n",
              "mean     27.255159    63.924953     4.507505     4.629456     6.771107  ...   \n",
              "std      32.524467   295.290407    21.800772     5.129006     8.363017  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       6.000000     0.000000     1.000000     1.000000     2.000000  ...   \n",
              "50%      17.000000     3.000000     1.000000     3.000000     4.000000  ...   \n",
              "75%      36.000000    21.000000     3.000000     6.000000     9.000000  ...   \n",
              "max     288.000000  6692.000000   498.000000    37.000000   103.000000  ...   \n",
              "\n",
              "                ic          cbm          amc           nr          ndc  \\\n",
              "count  1066.000000  1066.000000  1066.000000  1066.000000  1066.000000   \n",
              "mean      0.621951     1.072233    21.037765     6.332083     2.689493   \n",
              "std       0.849549     2.066372    65.173374     7.239202     2.110609   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     7.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000    14.055556     5.000000     3.000000   \n",
              "75%       1.000000     1.000000    25.918651     9.000000     4.000000   \n",
              "max       5.000000    19.000000  2052.000000    63.000000     9.000000   \n",
              "\n",
              "               nml         ndpv      max(cc)      avg(cc)         bugs  \n",
              "count  1066.000000  1066.000000  1066.000000  1066.000000  1066.000000  \n",
              "mean    142.507505     0.171670     3.926829     1.228445     0.155722  \n",
              "std     240.679941     0.717052     5.621412     0.854455     0.362762  \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "25%       0.000000     0.000000     1.000000     0.666667     0.000000  \n",
              "50%      86.000000     0.000000     2.000000     1.000000     0.000000  \n",
              "75%     150.000000     0.000000     5.000000     1.500000     0.000000  \n",
              "max    3158.000000    10.000000    53.000000     6.777778     1.000000  \n",
              "\n",
              "[8 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44476d58-a7ab-4d66-bc33-20738166da44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>version</th>\n",
              "      <th>wmc</th>\n",
              "      <th>dit</th>\n",
              "      <th>noc</th>\n",
              "      <th>cbo</th>\n",
              "      <th>rfc</th>\n",
              "      <th>lcom</th>\n",
              "      <th>ca</th>\n",
              "      <th>ce</th>\n",
              "      <th>npm</th>\n",
              "      <th>...</th>\n",
              "      <th>ic</th>\n",
              "      <th>cbm</th>\n",
              "      <th>amc</th>\n",
              "      <th>nr</th>\n",
              "      <th>ndc</th>\n",
              "      <th>nml</th>\n",
              "      <th>ndpv</th>\n",
              "      <th>max(cc)</th>\n",
              "      <th>avg(cc)</th>\n",
              "      <th>bugs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.066000e+03</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "      <td>1066.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.700000e+00</td>\n",
              "      <td>8.994371</td>\n",
              "      <td>2.331144</td>\n",
              "      <td>0.565666</td>\n",
              "      <td>8.756098</td>\n",
              "      <td>27.255159</td>\n",
              "      <td>63.924953</td>\n",
              "      <td>4.507505</td>\n",
              "      <td>4.629456</td>\n",
              "      <td>6.771107</td>\n",
              "      <td>...</td>\n",
              "      <td>0.621951</td>\n",
              "      <td>1.072233</td>\n",
              "      <td>21.037765</td>\n",
              "      <td>6.332083</td>\n",
              "      <td>2.689493</td>\n",
              "      <td>142.507505</td>\n",
              "      <td>0.171670</td>\n",
              "      <td>3.926829</td>\n",
              "      <td>1.228445</td>\n",
              "      <td>0.155722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.221488e-16</td>\n",
              "      <td>10.674262</td>\n",
              "      <td>1.320871</td>\n",
              "      <td>4.051998</td>\n",
              "      <td>22.469313</td>\n",
              "      <td>32.524467</td>\n",
              "      <td>295.290407</td>\n",
              "      <td>21.800772</td>\n",
              "      <td>5.129006</td>\n",
              "      <td>8.363017</td>\n",
              "      <td>...</td>\n",
              "      <td>0.849549</td>\n",
              "      <td>2.066372</td>\n",
              "      <td>65.173374</td>\n",
              "      <td>7.239202</td>\n",
              "      <td>2.110609</td>\n",
              "      <td>240.679941</td>\n",
              "      <td>0.717052</td>\n",
              "      <td>5.621412</td>\n",
              "      <td>0.854455</td>\n",
              "      <td>0.362762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.700000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.700000e+00</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.700000e+00</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.055556</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.700000e+00</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25.918651</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.700000e+00</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>499.000000</td>\n",
              "      <td>288.000000</td>\n",
              "      <td>6692.000000</td>\n",
              "      <td>498.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>2052.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>3158.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>6.777778</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44476d58-a7ab-4d66-bc33-20738166da44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44476d58-a7ab-4d66-bc33-20738166da44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44476d58-a7ab-4d66-bc33-20738166da44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MetaFeatureVectorFunc(list_of_projects):\n",
        "    temp_list_projects = list_of_projects.copy()\n",
        "    temparr = []\n",
        "    for  source_project in temp_list_projects:\n",
        "        datasetSource = pd.read_excel(source_project)\n",
        "        Features = datasetSource.columns.tolist()\n",
        "        ##filter the columns to remove data we do not want\n",
        "        Features = [c for c in Features if c not in [\"bugs\",\"version\",\"class\"]]\n",
        "        datasetSource = datasetSource[Features]\n",
        "        average=datasetSource.mean()\n",
        "        standardDeviation=datasetSource.std()\n",
        "        metafeatureVector=np.concatenate((average.values,standardDeviation.values), axis=0)\n",
        "        temparr.append(metafeatureVector)\n",
        "    return np.array(temparr)"
      ],
      "metadata": {
        "id": "4vaXw2yPGxXo"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#source_project = ant   # directory to target project\n",
        "\n",
        "metafeatureVectors = MetaFeatureVectorFunc(list_of_projects)"
      ],
      "metadata": {
        "id": "57ZyHe3_VlJa"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metafeatureVectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxZY9pKbWRUs",
        "outputId": "9f84df3b-4407-4ba9-f246-8d2d00224a9b"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.99437148e+00, 2.33114447e+00, 5.65666041e-01, 8.75609756e+00,\n",
              "        2.72551595e+01, 6.39249531e+01, 4.50750469e+00, 4.62945591e+00,\n",
              "        6.77110694e+00, 9.96845536e-01, 2.17337711e+02, 5.97031769e-01,\n",
              "        6.66979362e-01, 5.05197489e-01, 5.27834116e-01, 6.21951220e-01,\n",
              "        1.07223265e+00, 2.10377651e+01, 6.33208255e+00, 2.68949343e+00,\n",
              "        1.42507505e+02, 1.71669794e-01, 3.92682927e+00, 1.22844549e+00,\n",
              "        1.06742622e+01, 1.32087110e+00, 4.05199810e+00, 2.24693131e+01,\n",
              "        3.25244667e+01, 2.95290407e+02, 2.18007718e+01, 5.12900571e+00,\n",
              "        8.36301662e+00, 6.59347805e-01, 3.62065012e+02, 4.44866730e-01,\n",
              "        1.28142294e+00, 4.05656735e-01, 2.64390204e-01, 8.49549089e-01,\n",
              "        2.06637241e+00, 6.51733736e+01, 7.23920227e+00, 2.11060864e+00,\n",
              "        2.40679941e+02, 7.17052147e-01, 5.62141217e+00, 8.54454962e-01],\n",
              "       [7.28035144e+00, 1.78514377e+00, 4.16134185e-01, 9.56070288e+00,\n",
              "        1.86389776e+01, 6.15327476e+01, 4.34025559e+00, 5.83706070e+00,\n",
              "        5.76916933e+00, 1.00059433e+00, 9.95191693e+01, 4.92273590e-01,\n",
              "        7.14856230e-01, 3.53081173e-01, 5.08965047e-01, 3.37859425e-01,\n",
              "        7.76357827e-01, 1.16396388e+01, 1.26757188e+00, 6.69329073e-01,\n",
              "        1.97308307e+01, 2.66773163e-01, 2.10063898e+00, 9.23872972e-01,\n",
              "        1.01490332e+01, 1.20125290e+00, 2.32942360e+00, 2.00151898e+01,\n",
              "        2.27402322e+01, 4.60928313e+02, 1.91224137e+01, 6.38736014e+00,\n",
              "        9.20997139e+00, 7.54864455e-01, 1.59153056e+02, 4.88876852e-01,\n",
              "        1.18247382e+00, 4.15121879e-01, 2.49879030e-01, 5.71145695e-01,\n",
              "        2.31931041e+00, 1.22236954e+01, 3.12558400e+00, 1.17701890e+00,\n",
              "        8.93956541e+01, 1.06273923e+00, 2.60008600e+00, 6.79038677e-01],\n",
              "       [9.55765199e+00, 1.66876310e+00, 2.76729560e-01, 1.08846960e+01,\n",
              "        2.86855346e+01, 1.01549266e+02, 5.47169811e+00, 4.48846960e+00,\n",
              "        7.45702306e+00, 9.85335274e-01, 2.11761006e+02, 6.65082262e-01,\n",
              "        7.46331237e-01, 2.51916691e-01, 5.09535569e-01, 3.12368973e-01,\n",
              "        5.30398323e-01, 1.78292800e+01, 5.97274633e+00, 1.24318658e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 3.04192872e+00, 1.18162818e+00,\n",
              "        1.37307286e+01, 1.15923817e+00, 1.14447127e+00, 1.49354816e+01,\n",
              "        4.08968479e+01, 6.15177685e+02, 1.22195315e+01, 8.09881029e+00,\n",
              "        1.13042686e+01, 6.76266394e-01, 4.03873599e+02, 4.51504273e-01,\n",
              "        1.32549823e+00, 3.76098155e-01, 2.47787640e-01, 6.77453560e-01,\n",
              "        1.57368674e+00, 2.53316343e+01, 8.13549202e+00, 9.82825583e-01,\n",
              "        0.00000000e+00, 0.00000000e+00, 3.69622833e+00, 8.54325277e-01],\n",
              "       [7.07970343e+00, 2.06950880e+00, 2.13160334e-01, 8.68303985e+00,\n",
              "        2.41510658e+01, 1.13627433e+02, 4.90732159e+00, 4.85820204e+00,\n",
              "        4.41983318e+00, 8.29416971e-01, 2.18057461e+02, 2.96169235e-01,\n",
              "        9.49953661e-01, 3.68714000e-01, 5.33487912e-01, 3.81835032e-01,\n",
              "        8.77664504e-01, 2.37900451e+01, 3.97590361e+00, 1.35217794e+00,\n",
              "        1.20114921e+02, 9.63855422e-02, 4.61353105e+00, 1.55265013e+00,\n",
              "        1.69171600e+01, 1.72178739e+00, 1.66235553e+00, 1.77565896e+01,\n",
              "        4.08533099e+01, 1.46884917e+03, 1.52034054e+01, 6.72445382e+00,\n",
              "        1.08008974e+01, 7.54249851e-01, 6.46119219e+02, 4.27540681e-01,\n",
              "        1.50426034e+00, 4.34653135e-01, 2.33629324e-01, 7.80492665e-01,\n",
              "        2.37797791e+00, 2.88362497e+01, 1.05510234e+01, 1.97530496e+00,\n",
              "        5.21213569e+02, 6.31557182e-01, 8.15389105e+00, 1.58974969e+00],\n",
              "       [6.71276596e+00, 1.65602837e+00, 1.98581560e-01, 6.19503546e+00,\n",
              "        2.01099291e+01, 3.92304965e+01, 3.42907801e+00, 3.36879433e+00,\n",
              "        4.34751773e+00, 8.01499032e-01, 1.43734043e+02, 4.78913629e-01,\n",
              "        9.39716312e-01, 2.80453365e-01, 5.01592071e-01, 2.87234043e-01,\n",
              "        4.60992908e-01, 1.76292793e+01, 2.40070922e+00, 8.90070922e-01,\n",
              "        0.00000000e+00, 2.94326241e-01, 2.83687943e+00, 1.14245608e+00,\n",
              "        8.73405696e+00, 1.20738350e+00, 9.74550599e-01, 8.54426886e+00,\n",
              "        2.57716217e+01, 2.98197551e+02, 7.48024244e+00, 4.20457529e+00,\n",
              "        5.35565795e+00, 6.77030939e-01, 2.30074079e+02, 4.65015964e-01,\n",
              "        1.44652631e+00, 3.95306539e-01, 2.27083457e-01, 5.58767207e-01,\n",
              "        1.12251453e+00, 1.70139064e+01, 4.87046435e+00, 8.92021174e-01,\n",
              "        0.00000000e+00, 1.00633389e+00, 2.89833457e+00, 7.76463648e-01],\n",
              "       [7.97308489e+00, 1.74327122e+00, 4.90683230e-01, 8.34989648e+00,\n",
              "        1.98488613e+01, 4.18592133e+01, 4.36853002e+00, 4.53209110e+00,\n",
              "        5.12008282e+00, 9.57650295e-01, 2.20747412e+02, 4.83964250e-01,\n",
              "        1.23395445e+00, 3.27497710e-01, 4.72112817e-01, 4.74120083e-01,\n",
              "        1.10559006e+00, 2.01436296e+01, 1.74120083e+00, 8.44720497e-01,\n",
              "        1.00801242e+02, 7.57763975e-01, 3.23602484e+00, 1.09102481e+00,\n",
              "        1.12959665e+01, 8.69212492e-01, 1.65154779e+00, 9.15154427e+00,\n",
              "        2.76278607e+01, 3.50877556e+02, 8.05304015e+00, 5.36746241e+00,\n",
              "        7.11480182e+00, 6.61672796e-01, 5.45229689e+02, 4.53903787e-01,\n",
              "        1.96576674e+00, 3.51141088e-01, 2.38461005e-01, 6.51246015e-01,\n",
              "        1.93976455e+00, 2.44412646e+01, 4.55502324e+00, 1.03201253e+00,\n",
              "        5.71812651e+02, 2.63264630e+00, 7.15812702e+00, 1.12077601e+00],\n",
              "       [8.51562500e+00, 1.37500000e+00, 9.37500000e-02, 4.37500000e+00,\n",
              "        2.44531250e+01, 9.43750000e+01, 2.42187500e+00, 2.42187500e+00,\n",
              "        5.96875000e+00, 1.04063024e+00, 2.54468750e+02, 5.56640626e-01,\n",
              "        5.78125000e-01, 1.88376751e-01, 5.17258334e-01, 2.18750000e-01,\n",
              "        4.06250000e-01, 1.65972411e+01, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 4.53125000e-01, 2.78125000e+00, 9.21277146e-01,\n",
              "        1.29993799e+01, 7.66356045e-01, 6.35428864e-01, 5.14087263e+00,\n",
              "        4.25093565e+01, 4.64766284e+02, 2.81608017e+00, 4.47144268e+00,\n",
              "        6.95328802e+00, 7.47773430e-01, 6.81017306e+02, 4.80630510e-01,\n",
              "        1.17924764e+00, 3.63737575e-01, 2.76804854e-01, 5.18506708e-01,\n",
              "        1.21784027e+00, 1.84365093e+01, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 9.74755769e-01, 5.52761825e+00, 5.08290105e-01],\n",
              "       [1.20282486e+01, 1.85875706e+00, 6.25235405e-01, 8.78719397e+00,\n",
              "        2.64802260e+01, 8.51902072e+01, 4.60451977e+00, 4.61205273e+00,\n",
              "        1.01977401e+01, 1.00382865e+00, 2.51143126e+02, 3.98697048e-01,\n",
              "        7.53295669e-01, 3.75125491e-01, 4.49570342e-01, 5.16007533e-01,\n",
              "        1.73258004e+00, 1.75056895e+01, 2.72881356e+00, 2.05461394e+00,\n",
              "        0.00000000e+00, 9.32203390e-01, 3.33898305e+00, 1.11940675e+00,\n",
              "        1.38569904e+01, 8.10784362e-01, 6.36179959e+00, 1.81256075e+01,\n",
              "        3.49554040e+01, 4.04857967e+02, 1.61448017e+01, 8.39160439e+00,\n",
              "        1.20600883e+01, 5.23566832e-01, 5.83868180e+02, 4.09111633e-01,\n",
              "        2.35471495e+00, 3.16312825e-01, 2.70949956e-01, 5.77264100e-01,\n",
              "        2.44795886e+00, 3.63750786e+01, 2.38665676e+00, 1.36907640e+00,\n",
              "        0.00000000e+00, 1.33427906e+00, 7.10367737e+00, 1.02760455e+00],\n",
              "       [6.33342833e+00, 1.92476489e+00, 3.08064976e-01, 1.11977771e+01,\n",
              "        2.51516101e+01, 4.10245084e+01, 3.01111428e+00, 8.42205757e+00,\n",
              "        4.57651753e+00, 1.24569582e+00, 1.94365631e+02, 3.36057305e-01,\n",
              "        2.30265033e-01, 3.78688007e-01, 5.28264012e-01, 4.41151325e-01,\n",
              "        8.19321744e-01, 2.55318010e+01, 5.61983471e-01, 4.23482474e-01,\n",
              "        2.46543175e+01, 2.10316329e-01, 4.16728413e+00, 1.50185882e+00,\n",
              "        8.67636616e+00, 1.25419910e+00, 2.55765790e+00, 1.52788854e+01,\n",
              "        3.22735923e+01, 2.63813275e+02, 1.08233795e+01, 1.03195513e+01,\n",
              "        7.55241481e+00, 6.30727649e-01, 4.04950127e+02, 3.88671524e-01,\n",
              "        6.83313464e-01, 4.24047095e-01, 2.65216936e-01, 7.15342880e-01,\n",
              "        2.07934472e+00, 3.17928587e+01, 1.49321619e+00, 9.81979165e-01,\n",
              "        1.34925115e+02, 8.23816408e-01, 7.46467936e+00, 1.62026236e+00],\n",
              "       [7.44776119e+00, 1.63059701e+00, 3.91791045e-01, 1.23134328e+01,\n",
              "        2.87089552e+01, 3.93432836e+01, 4.11940299e+00, 8.44029851e+00,\n",
              "        5.92910448e+00, 1.11405954e+00, 2.03070896e+02, 5.92887629e-01,\n",
              "        3.88059701e-01, 3.19437668e-01, 4.94162602e-01, 2.16417910e-01,\n",
              "        4.29104478e-01, 2.76742282e+01, 2.96641791e+00, 1.54850746e+00,\n",
              "        8.24216418e+01, 3.61940299e-01, 7.50373134e+00, 2.07783648e+00,\n",
              "        8.93888292e+00, 7.75150353e-01, 2.13921994e+00, 1.17329319e+01,\n",
              "        2.56955160e+01, 1.72009498e+02, 9.90142030e+00, 6.99332072e+00,\n",
              "        8.52615561e+00, 6.69808581e-01, 2.30339854e+02, 4.72237477e-01,\n",
              "        8.33839077e-01, 3.65979328e-01, 2.21616606e-01, 5.38578241e-01,\n",
              "        1.14436084e+00, 2.64262606e+01, 3.11736574e+00, 1.16819494e+00,\n",
              "        1.38737369e+02, 8.82395002e-01, 8.68012415e+00, 1.72995977e+00],\n",
              "       [8.29885057e+00, 1.63601533e+00, 3.86973180e-01, 9.93486590e+00,\n",
              "        2.09770115e+01, 7.06590038e+01, 5.09195402e+00, 5.54789272e+00,\n",
              "        6.58237548e+00, 1.21596055e+00, 2.24977011e+02, 4.48083496e-01,\n",
              "        5.05747126e-01, 3.61461682e-01, 4.60474793e-01, 2.87356322e-01,\n",
              "        4.48275862e-01, 1.84504207e+01, 2.13409962e+00, 9.54022989e-01,\n",
              "        0.00000000e+00, 0.00000000e+00, 3.70881226e+00, 1.20537445e+00,\n",
              "        1.34067563e+01, 8.86699706e-01, 2.58391155e+00, 1.21566526e+01,\n",
              "        2.62835033e+01, 5.20250334e+02, 1.05633243e+01, 7.31979701e+00,\n",
              "        8.44062496e+00, 7.19595149e-01, 9.70800050e+02, 4.68888147e-01,\n",
              "        1.11155016e+00, 4.12001277e-01, 2.31926675e-01, 5.31501052e-01,\n",
              "        1.00106045e+00, 2.67904915e+01, 2.98090494e+00, 7.88006921e-01,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.37028730e+01, 1.76964619e+00],\n",
              "       [9.03266332e+00, 2.33919598e+00, 4.32160804e-01, 9.73785595e+00,\n",
              "        2.39530988e+01, 9.68157454e+01, 4.71775544e+00, 5.74706868e+00,\n",
              "        7.09128978e+00, 1.05848980e+00, 3.71104690e+02, 5.05153995e-01,\n",
              "        7.83919598e-01, 4.91854524e-01, 5.20658064e-01, 6.88442211e-01,\n",
              "        2.31574539e+00, 6.45081875e+01, 9.92462312e-01, 7.62144054e-01,\n",
              "        2.11901173e+01, 5.11725293e-01, 4.09380235e+00, 1.32458228e+00,\n",
              "        1.47202960e+01, 1.40756715e+00, 2.20663577e+00, 1.60859737e+01,\n",
              "        3.42359469e+01, 5.24052749e+02, 1.32044940e+01, 8.23347565e+00,\n",
              "        1.30739418e+01, 6.60878064e-01, 7.08464039e+02, 4.60465090e-01,\n",
              "        1.51058053e+00, 4.45452194e-01, 2.55660273e-01, 1.03180784e+00,\n",
              "        4.28588240e+00, 1.64962061e+02, 1.50743676e+00, 9.11162458e-01,\n",
              "        9.30453379e+01, 9.15698903e-01, 6.80216758e+00, 1.26889643e+00],\n",
              "       [9.24143070e+00, 1.91952310e+00, 3.87481371e-01, 5.98658718e+00,\n",
              "        1.81490313e+01, 6.63830104e+01, 3.15350224e+00, 3.15797317e+00,\n",
              "        7.26229508e+00, 1.37428924e+00, 2.29506706e+02, 2.86115533e-01,\n",
              "        7.58569300e-01, 3.48002925e-01, 5.29302904e-01, 3.63636364e-01,\n",
              "        1.36512668e+00, 1.86089001e+01, 1.01490313e+00, 6.69150522e-01,\n",
              "        1.76540984e+02, 1.31147541e-01, 3.64083458e+00, 1.35495169e+00,\n",
              "        1.05816575e+01, 1.22757755e+00, 2.60288441e+00, 8.64445982e+00,\n",
              "        2.45380940e+01, 2.01350977e+02, 6.75489753e+00, 5.18310327e+00,\n",
              "        8.24619642e+00, 7.16084046e-01, 5.73938961e+02, 4.23104296e-01,\n",
              "        2.36608128e+00, 4.24508843e-01, 2.49778748e-01, 6.96765156e-01,\n",
              "        3.01873354e+00, 3.44612908e+01, 1.88547115e+00, 8.48661295e-01,\n",
              "        4.56294934e+02, 6.56152303e-01, 8.82655771e+00, 1.72900194e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KD TREE to calculate distance\n",
        "from scipy.spatial import KDTree\n",
        "tempMscoreArray = []\n",
        "def MatchingScore(x):\n",
        "  T = KDTree(metafeatureVectors)\n",
        "  distance, idc = T.query(x, k=13, p=2)\n",
        "  return(1/1+distance,idc)\n",
        "  \n"
      ],
      "metadata": {
        "id": "KZ4QhR7qbxrg"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MScore,idc = MatchingScore(metafeatureVectors)"
      ],
      "metadata": {
        "id": "AgiSKJUNd8us"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(MScore) # print matching score in ascending order\n",
        "idc # print project index sorted in most similar to least similar\n",
        "# project index ant = 0, camel=1, ivy=2,jedit=3, log4j=4, lucene=5, pbeans=6, poi=7, prop=8,synapse=9,velocity=10, xalan=11, xer=12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "841X2umSeYbC",
        "outputId": "0cea8cd8-d31f-43d9-ec0d-3f544c7d2cd2"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.00000000e+00 1.75392943e+02 2.23055350e+02 3.22125128e+02\n",
            "  3.24418444e+02 3.52574852e+02 3.77875691e+02 3.89180531e+02\n",
            "  4.31845977e+02 4.63735075e+02 4.96650344e+02 7.09111966e+02\n",
            "  1.24243479e+03]\n",
            " [1.00000000e+00 2.07718643e+02 3.28009746e+02 3.28202982e+02\n",
            "  3.35143346e+02 3.52574852e+02 4.66203467e+02 5.54975269e+02\n",
            "  6.39088976e+02 6.46039235e+02 6.46335724e+02 8.29885661e+02\n",
            "  1.21232471e+03]\n",
            " [1.00000000e+00 2.81620688e+02 3.20003719e+02 3.28202982e+02\n",
            "  3.74865273e+02 3.83891236e+02 3.97792921e+02 4.31845977e+02\n",
            "  5.07936725e+02 5.77186286e+02 6.57521208e+02 6.65670971e+02\n",
            "  1.03727645e+03]\n",
            " [1.00000000e+00 1.03727645e+03 1.06575940e+03 1.12731339e+03\n",
            "  1.13839881e+03 1.14024672e+03 1.19442139e+03 1.21232471e+03\n",
            "  1.24243479e+03 1.27465742e+03 1.29512640e+03 1.35798904e+03\n",
            "  1.41825830e+03]\n",
            " [1.00000000e+00 2.07718643e+02 2.15273349e+02 2.32700415e+02\n",
            "  3.24418444e+02 3.74865273e+02 3.89694475e+02 4.97793946e+02\n",
            "  6.07993190e+02 6.13767155e+02 6.68290493e+02 7.79387395e+02\n",
            "  1.35798904e+03]\n",
            " [1.00000000e+00 2.08590601e+02 3.89180531e+02 4.75217007e+02\n",
            "  5.66321122e+02 5.83884657e+02 5.88236643e+02 6.11600798e+02\n",
            "  6.46039235e+02 6.57521208e+02 6.68290493e+02 7.41186201e+02\n",
            "  1.12731339e+03]\n",
            " [1.00000000e+00 1.19383998e+02 2.27216400e+02 2.99480967e+02\n",
            "  3.20003719e+02 3.78566579e+02 4.63735075e+02 4.97793946e+02\n",
            "  5.54975269e+02 5.67831446e+02 5.68738207e+02 6.11600798e+02\n",
            "  1.14024672e+03]\n",
            " [1.00000000e+00 1.19383998e+02 2.69662434e+02 2.77025506e+02\n",
            "  2.81620688e+02 3.77875691e+02 3.89694475e+02 4.06346047e+02\n",
            "  4.59453558e+02 4.66203467e+02 5.32184861e+02 5.88236643e+02\n",
            "  1.19442139e+03]\n",
            " [1.00000000e+00 1.75392943e+02 2.07135165e+02 2.32700415e+02\n",
            "  2.77025506e+02 3.35143346e+02 3.78566579e+02 3.83891236e+02\n",
            "  4.02269668e+02 4.65039022e+02 4.75217007e+02 6.38819216e+02\n",
            "  1.29512640e+03]\n",
            " [1.00000000e+00 2.07135165e+02 2.15273349e+02 2.23055350e+02\n",
            "  3.28009746e+02 4.59453558e+02 4.81042540e+02 5.07936725e+02\n",
            "  5.66321122e+02 5.67831446e+02 6.41858302e+02 8.36032904e+02\n",
            "  1.41825830e+03]\n",
            " [1.00000000e+00 2.99480967e+02 3.49395434e+02 4.06346047e+02\n",
            "  5.77186286e+02 6.38819216e+02 7.07240388e+02 7.09111966e+02\n",
            "  7.41186201e+02 7.79387395e+02 8.29885661e+02 8.36032904e+02\n",
            "  1.13839881e+03]\n",
            " [1.00000000e+00 2.27216400e+02 2.69662434e+02 3.49395434e+02\n",
            "  3.97792921e+02 4.65039022e+02 4.96650344e+02 5.65568469e+02\n",
            "  5.83884657e+02 6.07993190e+02 6.39088976e+02 6.41858302e+02\n",
            "  1.06575940e+03]\n",
            " [1.00000000e+00 2.08590601e+02 3.22125128e+02 4.02269668e+02\n",
            "  4.81042540e+02 5.32184861e+02 5.65568469e+02 5.68738207e+02\n",
            "  6.13767155e+02 6.46335724e+02 6.65670971e+02 7.07240388e+02\n",
            "  1.27465742e+03]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  8,  9, 12,  4,  1,  7,  5,  2,  6, 11, 10,  3],\n",
              "       [ 1,  4,  9,  2,  8,  0,  7,  6, 11,  5, 12, 10,  3],\n",
              "       [ 2,  7,  6,  1,  4,  8, 11,  0,  9, 10,  5, 12,  3],\n",
              "       [ 3,  2, 11,  5, 10,  6,  7,  1,  0, 12,  8,  4,  9],\n",
              "       [ 4,  1,  9,  8,  0,  2,  7,  6, 11, 12,  5, 10,  3],\n",
              "       [ 5, 12,  0,  8,  9, 11,  7,  6,  1,  2,  4, 10,  3],\n",
              "       [ 6,  7, 11, 10,  2,  8,  0,  4,  1,  9, 12,  5,  3],\n",
              "       [ 7,  6, 11,  8,  2,  0,  4, 10,  9,  1, 12,  5,  3],\n",
              "       [ 8,  0,  9,  4,  7,  1,  6,  2, 12, 11,  5, 10,  3],\n",
              "       [ 9,  8,  4,  0,  1,  7, 12,  2,  5,  6, 11, 10,  3],\n",
              "       [10,  6, 11,  7,  2,  8, 12,  0,  5,  4,  1,  9,  3],\n",
              "       [11,  6,  7, 10,  2,  8,  0, 12,  5,  4,  1,  9,  3],\n",
              "       [12,  5,  0,  8,  9,  7, 11,  6,  4,  1,  2, 10,  3]])"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MatchingScore = [M[np.argsort(i)] for M,i in zip(MScore,idc)]\n",
        "MatchingScore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJCYjaXtLnH3",
        "outputId": "391c1c1c-f8ee-4954-a51d-e33a9a1b8241"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.00000000e+00, 3.52574852e+02, 4.31845977e+02, 1.24243479e+03,\n",
              "        3.24418444e+02, 3.89180531e+02, 4.63735075e+02, 3.77875691e+02,\n",
              "        1.75392943e+02, 2.23055350e+02, 7.09111966e+02, 4.96650344e+02,\n",
              "        3.22125128e+02]),\n",
              " array([3.52574852e+02, 1.00000000e+00, 3.28202982e+02, 1.21232471e+03,\n",
              "        2.07718643e+02, 6.46039235e+02, 5.54975269e+02, 4.66203467e+02,\n",
              "        3.35143346e+02, 3.28009746e+02, 8.29885661e+02, 6.39088976e+02,\n",
              "        6.46335724e+02]),\n",
              " array([4.31845977e+02, 3.28202982e+02, 1.00000000e+00, 1.03727645e+03,\n",
              "        3.74865273e+02, 6.57521208e+02, 3.20003719e+02, 2.81620688e+02,\n",
              "        3.83891236e+02, 5.07936725e+02, 5.77186286e+02, 3.97792921e+02,\n",
              "        6.65670971e+02]),\n",
              " array([1.24243479e+03, 1.21232471e+03, 1.03727645e+03, 1.00000000e+00,\n",
              "        1.35798904e+03, 1.12731339e+03, 1.14024672e+03, 1.19442139e+03,\n",
              "        1.29512640e+03, 1.41825830e+03, 1.13839881e+03, 1.06575940e+03,\n",
              "        1.27465742e+03]),\n",
              " array([3.24418444e+02, 2.07718643e+02, 3.74865273e+02, 1.35798904e+03,\n",
              "        1.00000000e+00, 6.68290493e+02, 4.97793946e+02, 3.89694475e+02,\n",
              "        2.32700415e+02, 2.15273349e+02, 7.79387395e+02, 6.07993190e+02,\n",
              "        6.13767155e+02]),\n",
              " array([3.89180531e+02, 6.46039235e+02, 6.57521208e+02, 1.12731339e+03,\n",
              "        6.68290493e+02, 1.00000000e+00, 6.11600798e+02, 5.88236643e+02,\n",
              "        4.75217007e+02, 5.66321122e+02, 7.41186201e+02, 5.83884657e+02,\n",
              "        2.08590601e+02]),\n",
              " array([4.63735075e+02, 5.54975269e+02, 3.20003719e+02, 1.14024672e+03,\n",
              "        4.97793946e+02, 6.11600798e+02, 1.00000000e+00, 1.19383998e+02,\n",
              "        3.78566579e+02, 5.67831446e+02, 2.99480967e+02, 2.27216400e+02,\n",
              "        5.68738207e+02]),\n",
              " array([3.77875691e+02, 4.66203467e+02, 2.81620688e+02, 1.19442139e+03,\n",
              "        3.89694475e+02, 5.88236643e+02, 1.19383998e+02, 1.00000000e+00,\n",
              "        2.77025506e+02, 4.59453558e+02, 4.06346047e+02, 2.69662434e+02,\n",
              "        5.32184861e+02]),\n",
              " array([1.75392943e+02, 3.35143346e+02, 3.83891236e+02, 1.29512640e+03,\n",
              "        2.32700415e+02, 4.75217007e+02, 3.78566579e+02, 2.77025506e+02,\n",
              "        1.00000000e+00, 2.07135165e+02, 6.38819216e+02, 4.65039022e+02,\n",
              "        4.02269668e+02]),\n",
              " array([2.23055350e+02, 3.28009746e+02, 5.07936725e+02, 1.41825830e+03,\n",
              "        2.15273349e+02, 5.66321122e+02, 5.67831446e+02, 4.59453558e+02,\n",
              "        2.07135165e+02, 1.00000000e+00, 8.36032904e+02, 6.41858302e+02,\n",
              "        4.81042540e+02]),\n",
              " array([7.09111966e+02, 8.29885661e+02, 5.77186286e+02, 1.13839881e+03,\n",
              "        7.79387395e+02, 7.41186201e+02, 2.99480967e+02, 4.06346047e+02,\n",
              "        6.38819216e+02, 8.36032904e+02, 1.00000000e+00, 3.49395434e+02,\n",
              "        7.07240388e+02]),\n",
              " array([4.96650344e+02, 6.39088976e+02, 3.97792921e+02, 1.06575940e+03,\n",
              "        6.07993190e+02, 5.83884657e+02, 2.27216400e+02, 2.69662434e+02,\n",
              "        4.65039022e+02, 6.41858302e+02, 3.49395434e+02, 1.00000000e+00,\n",
              "        5.65568469e+02]),\n",
              " array([3.22125128e+02, 6.46335724e+02, 6.65670971e+02, 1.27465742e+03,\n",
              "        6.13767155e+02, 2.08590601e+02, 5.68738207e+02, 5.32184861e+02,\n",
              "        4.02269668e+02, 4.81042540e+02, 7.07240388e+02, 5.65568469e+02,\n",
              "        1.00000000e+00])]"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the Matching score in text File\n",
        "np.savetxt(\"Mscore.csv\", MScore)"
      ],
      "metadata": {
        "id": "atCwcE2liCe2"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Genearting Usability Score**"
      ],
      "metadata": {
        "id": "ounG3wJkjnqk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "OB6eVTUA40ns"
      },
      "outputs": [],
      "source": [
        "#Calculating Usability score by taking AUC as Performance Measure\n",
        "names = [\"Naive Bayes\", \"Logistic Regression\", \"RandomForestClassifier\",\"DecisionTreeClassifier\",\"SVC\"]\n",
        "classifiers = [GaussianNB(),LogisticRegression(), RandomForestClassifier(),DecisionTreeClassifier(), SVC()]\n",
        "score = 0\n",
        "results = []\n",
        "output = []\n",
        "scoring = 'FScore'\n",
        "def perform_training(list_of_projects, target_project):\n",
        "    results = []\n",
        "    output = []\n",
        "    temp_list_projects = list_of_projects.copy()\n",
        "    datasetTarget = pd.read_excel(target_project)\n",
        "    temp_list_projects.remove(target_project)\n",
        "\n",
        "    for  index, source_project in enumerate(temp_list_projects):\n",
        "        results.append(f'Project No: {index+1}\\n')\n",
        "        datasetSource = pd.read_excel(source_project)\n",
        "        #print(datasetSource)\n",
        "        #Label Encoding for class column\n",
        "        from sklearn.preprocessing import LabelEncoder\n",
        "        label_encoder = preprocessing.LabelEncoder()\n",
        "        #dataset['Class']=le_class.fit_transform(dataset['Class']\n",
        "        datasetSource['class']= label_encoder.fit_transform(datasetSource['class'])\n",
        "        datasetTarget['class'] = label_encoder.fit_transform(datasetTarget['class'])\n",
        "        ##Create independent and dependent  features\n",
        "        columnsSource = datasetSource.columns.tolist()\n",
        "        columnsTarget = datasetTarget.columns.tolist()\n",
        "        ##filter the columns to remove data we do not want\n",
        "        columnsSource = [c for c in columnsSource if c not in [\"bugs\",\"Version\"]]\n",
        "        columnsTarget = [c for c in columnsTarget if c not in [\"bugs\",\"Version\"]]\n",
        "        ##store the variable we are predicting\n",
        "        targetSource=\"bugs\"\n",
        "        targetTarget=\"bugs\"\n",
        "        # define a random state\n",
        "        state = np.random.RandomState(42)\n",
        "        XSource = datasetSource[columnsSource]\n",
        "        ySource = datasetSource[targetSource]\n",
        "        XTarget = datasetTarget[columnsTarget]\n",
        "        yTarget = datasetTarget[targetTarget]\n",
        "        #X_outliers = state.uniform(low=0, high =1, size=(X.shape[0], X.shape[1]))\n",
        "\n",
        "        #splitting into train and test without random for prop as target and ant as source\n",
        "        train_data_X = XSource\n",
        "        test_data_X = XTarget\n",
        "        train_data_y = ySource\n",
        "        test_data_y = yTarget\n",
        "        #Print the shape of X & Y\n",
        "        print(XSource.shape)\n",
        "        print(ySource.shape)\n",
        "        print(XTarget.shape)\n",
        "        print(yTarget.shape)\n",
        "        #transform the dataset\n",
        "        #oversample = BorderlineSMOTE()\n",
        "        oversample = SMOTETomek()\n",
        "        train_data_X, train_data_y = oversample.fit_resample(train_data_X, train_data_y)\n",
        "        test_data_X, test_data_y = oversample.fit_resample(test_data_X, test_data_y)\n",
        "        print('Data Resampled')\n",
        "        # saving the performance in file\n",
        "        print(names,classifiers)\n",
        "        temp = []\n",
        "        for name, clf in zip(names, classifiers):\n",
        "            performance = clf.fit(train_data_X, train_data_y)\n",
        "            y_pred = clf.predict(test_data_X)\n",
        "            print(y_pred)\n",
        "            FScore  = f1_score(test_data_y, y_pred)\n",
        "            print('F1 Score', FScore)\n",
        "            #print(\"Accuracy:\",metrics.accuracy_score(test_data_y, y_pred))\n",
        "            results.append(f'Name: {name}\\tFScore: {FScore}\\n')\n",
        "            temp.append(FScore)\n",
        "            names.append(name)\n",
        "            #msg = \"Nested CV Accuracy %s: %f (+/- %f )\\n\" % (name, performance.mean()*100, performance.std()*100)\n",
        "            #print(msg)\n",
        "            #clf.fit(train_data_X, train_data_y)\n",
        "            #print('Test set accuracy: {:.2f}'.format(clf.score(test_data_X, test_data_Y)*100),  '%')\n",
        "            #print(\"Best Parameters: \\n{}\\n\".format(clf.best_params_))\n",
        "            #print(\"Best CV Score: \\n{}\\n\".format(clf.best_score_)) #average of all cv folds for a single combination of the parameters you specify \n",
        "        output.append(temp)\n",
        "        with open(\"FScore_As_PerformanceMeasure.csv\",\"w\") as file:\n",
        "          file.writelines(results)\n",
        "        \n",
        "    return np.array(output)\n",
        "\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh9j-9oX6AMC",
        "outputId": "2d78d25e-f4ba-4f6c-8d3c-186934230b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1252, 26)\n",
            "(1252,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.670982482863671\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.6754047802621435\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.6751445086705202\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.674633770239013\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7225217751970137\n",
            "(477, 26)\n",
            "(477,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 0 0 ... 1 0 1]\n",
            "F1 Score 0.6799724707501721\n",
            "[0 0 0 ... 1 0 1]\n",
            "F1 Score 0.6240115025161754\n",
            "[0 0 0 ... 1 1 1]\n",
            "F1 Score 0.7150684931506849\n",
            "[0 0 0 ... 0 1 0]\n",
            "F1 Score 0.14472361809045226\n",
            "[0 1 1 ... 1 1 1]\n",
            "F1 Score 0.7636579572446556\n",
            "(1079, 26)\n",
            "(1079,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 0 0 ... 0 0 0]\n",
            "F1 Score 0.5228548516439454\n",
            "[0 0 0 ... 0 0 1]\n",
            "F1 Score 0.599618077657543\n",
            "[0 0 0 ... 0 0 0]\n",
            "F1 Score 0.3000931966449208\n",
            "[0 0 0 ... 0 0 0]\n",
            "F1 Score 0.2796296296296296\n",
            "[0 0 0 ... 1 1 1]\n",
            "F1 Score 0.6055555555555555\n",
            "(282, 26)\n",
            "(282,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.726825266611977\n",
            "[1 1 0 ... 1 1 1]\n",
            "F1 Score 0.7244480784955029\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7295183202964183\n",
            "[1 1 1 ... 1 0 1]\n",
            "F1 Score 0.710681244743482\n",
            "[0 1 1 ... 1 1 1]\n",
            "F1 Score 0.7938718662952646\n",
            "(483, 26)\n",
            "(483,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 1 1 ... 1 0 1]\n",
            "F1 Score 0.8309572301425662\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7545375972342265\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.795688847235239\n",
            "[1 0 1 ... 1 1 1]\n",
            "F1 Score 0.7496296296296296\n",
            "[0 1 1 ... 1 1 1]\n",
            "F1 Score 0.8306172839506173\n",
            "(64, 26)\n",
            "(64,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 0 0 ... 1 1 0]\n",
            "F1 Score 0.6215673141326189\n",
            "[0 0 0 ... 1 1 0]\n",
            "F1 Score 0.6844014510278114\n",
            "[0 1 0 ... 1 1 0]\n",
            "F1 Score 0.728018757327081\n",
            "[0 1 0 ... 1 1 0]\n",
            "F1 Score 0.531331592689295\n",
            "[0 0 1 ... 1 1 0]\n",
            "F1 Score 0.7220405493786788\n",
            "(531, 26)\n",
            "(531,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 0 1 ... 0 1 1]\n",
            "F1 Score 0.8398458998348927\n",
            "[1 1 1 ... 0 1 1]\n",
            "F1 Score 0.7708055184690699\n",
            "[0 1 0 ... 1 1 1]\n",
            "F1 Score 0.8004115226337449\n",
            "[1 1 0 ... 1 1 1]\n",
            "F1 Score 0.7705159705159704\n",
            "[0 1 1 ... 1 1 1]\n",
            "F1 Score 0.8155543878087231\n",
            "(3509, 26)\n",
            "(3509,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7665352606219886\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7287784679089027\n",
            "[0 1 1 ... 1 0 1]\n",
            "F1 Score 0.5609436435124509\n",
            "[0 0 0 ... 0 0 1]\n",
            "F1 Score 0.5641952983725136\n",
            "[0 1 1 ... 1 1 1]\n",
            "F1 Score 0.7573240052470486\n",
            "(268, 26)\n",
            "(268,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.6737723639132089\n",
            "[1 1 0 ... 1 1 1]\n",
            "F1 Score 0.6797642436149312\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.6746062235881675\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.6746062235881675\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7750336775931747\n",
            "(261, 26)\n",
            "(261,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 0 1 ... 0 1 1]\n",
            "F1 Score 0.7243310516490356\n",
            "[0 1 1 ... 1 1 1]\n",
            "F1 Score 0.7604017216642756\n",
            "[0 0 0 ... 1 1 1]\n",
            "F1 Score 0.7530505520046483\n",
            "[1 0 0 ... 1 1 1]\n",
            "F1 Score 0.7463976945244957\n",
            "[0 1 1 ... 1 1 1]\n",
            "F1 Score 0.8081457663451231\n",
            "(1194, 26)\n",
            "(1194,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7493649449618968\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7137096774193548\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7239263803680982\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7418273260687342\n",
            "[0 1 1 ... 1 1 1]\n",
            "F1 Score 0.790009250693802\n",
            "(671, 26)\n",
            "(671,)\n",
            "(1066, 26)\n",
            "(1066,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7533020877716233\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7488352393053791\n",
            "[1 1 1 ... 1 1 1]\n",
            "F1 Score 0.7493627867459642\n",
            "[1 1 1 ... 1 0 1]\n",
            "F1 Score 0.7247119078104993\n",
            "[1 1 0 ... 1 0 1]\n",
            "F1 Score 0.7612334801762114\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.67098248, 0.67540478, 0.67514451, 0.67463377, 0.72252178],\n",
              "       [0.67997247, 0.6240115 , 0.71506849, 0.14472362, 0.76365796],\n",
              "       [0.52285485, 0.59961808, 0.3000932 , 0.27962963, 0.60555556],\n",
              "       [0.72682527, 0.72444808, 0.72951832, 0.71068124, 0.79387187],\n",
              "       [0.83095723, 0.7545376 , 0.79568885, 0.74962963, 0.83061728],\n",
              "       [0.62156731, 0.68440145, 0.72801876, 0.53133159, 0.72204055],\n",
              "       [0.8398459 , 0.77080552, 0.80041152, 0.77051597, 0.81555439],\n",
              "       [0.76653526, 0.72877847, 0.56094364, 0.5641953 , 0.75732401],\n",
              "       [0.67377236, 0.67976424, 0.67460622, 0.67460622, 0.77503368],\n",
              "       [0.72433105, 0.76040172, 0.75305055, 0.74639769, 0.80814577],\n",
              "       [0.74936494, 0.71370968, 0.72392638, 0.74182733, 0.79000925],\n",
              "       [0.75330209, 0.74883524, 0.74936279, 0.72471191, 0.76123348]])"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ],
      "source": [
        "target_project = ant   # directory to target project\n",
        "index_target_project=0\n",
        "FScores = perform_training(list_of_projects, target_project)\n",
        "FScores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "#Calculating Usability score by taking AUC as Performance Measure\n",
        "names = [\"Naive Bayes\", \"Logistic Regression\", \"RandomForestClassifier\",\"DecisionTreeClassifier\",\"SVC\"]\n",
        "classifiers = [GaussianNB(),LogisticRegression(), RandomForestClassifier(),DecisionTreeClassifier(), SVC()]\n",
        "score = 0\n",
        "results = []\n",
        "scoring = 'roc_auc_score'\n",
        "def perform_training(list_of_projects, target_project):\n",
        "    temp_list_projects = list_of_projects.copy()\n",
        "    datasetTarget = pd.read_excel(target_project)\n",
        "    temp_list_projects.remove(target_project)\n",
        "\n",
        "    for  index, source_project in enumerate(temp_list_projects):\n",
        "        results.append(f'Project No: {index+1}\\n')\n",
        "        datasetSource = pd.read_excel(source_project)\n",
        "        #print(datasetSource)\n",
        "        #Label Encoding for class column\n",
        "        from sklearn.preprocessing import LabelEncoder\n",
        "        label_encoder = preprocessing.LabelEncoder()\n",
        "        #dataset['Class']=le_class.fit_transform(dataset['Class']\n",
        "        datasetSource['class']= label_encoder.fit_transform(datasetSource['class'])\n",
        "        datasetTarget['class'] = label_encoder.fit_transform(datasetTarget['class'])\n",
        "        ##Create independent and dependent  features\n",
        "        columnsSource = datasetSource.columns.tolist()\n",
        "        columnsTarget = datasetTarget.columns.tolist()\n",
        "        ##filter the columns to remove data we do not want\n",
        "        columnsSource = [c for c in columnsSource if c not in [\"bugs\",\"Version\"]]\n",
        "        columnsTarget = [c for c in columnsTarget if c not in [\"bugs\",\"Version\"]]\n",
        "        ##store the variable we are predicting\n",
        "        targetSource=\"bugs\"\n",
        "        targetTarget=\"bugs\"\n",
        "        # define a random state\n",
        "        state = np.random.RandomState(42)\n",
        "        XSource = datasetSource[columnsSource]\n",
        "        ySource = datasetSource[targetSource]\n",
        "        XTarget = datasetTarget[columnsTarget]\n",
        "        yTarget = datasetTarget[targetTarget]\n",
        "        #X_outliers = state.uniform(low=0, high =1, size=(X.shape[0], X.shape[1]))\n",
        "\n",
        "        #splitting into train and test without random for prop as target and ant as source\n",
        "        train_data_X = XSource\n",
        "        test_data_X = XTarget\n",
        "        train_data_y = ySource\n",
        "        test_data_y = yTarget\n",
        "        #Print the shape of X & Y\n",
        "        print(XSource.shape)\n",
        "        print(ySource.shape)\n",
        "        print(XTarget.shape)\n",
        "        print(yTarget.shape)\n",
        "        #transform the dataset\n",
        "        #oversample = BorderlineSMOTE()\n",
        "        oversample = SMOTETomek()\n",
        "        train_data_X, train_data_y = oversample.fit_resample(train_data_X, train_data_y)\n",
        "        test_data_X, test_data_y = oversample.fit_resample(test_data_X, test_data_y)\n",
        "        print('Data Resampled')\n",
        "        # saving the performance in file\n",
        "        print(names,classifiers)\n",
        "        for name, clf in zip(names, classifiers):\n",
        "            performance = clf.fit(train_data_X, train_data_y)\n",
        "            y_pred = clf.predict(test_data_X)\n",
        "            print(y_pred)\n",
        "            AUC  = metrics.roc_auc_score(test_data_y, y_pred)\n",
        "            print('AUC', AUC)\n",
        "            #print(\"Accuracy:\",metrics.accuracy_score(test_data_y, y_pred))\n",
        "            results.append(f'Name: {name}\\tAUC: {AUC}\\n')\n",
        "            names.append(name)\n",
        "            #msg = \"Nested CV Accuracy %s: %f (+/- %f )\\n\" % (name, performance.mean()*100, performance.std()*100)\n",
        "            #print(msg)\n",
        "            #clf.fit(train_data_X, train_data_y)\n",
        "            #print('Test set accuracy: {:.2f}'.format(clf.score(test_data_X, test_data_Y)*100),  '%')\n",
        "            #print(\"Best Parameters: \\n{}\\n\".format(clf.best_params_))\n",
        "            #print(\"Best CV Score: \\n{}\\n\".format(clf.best_score_)) #average of all cv folds for a single combination of the parameters you specify \n",
        "\n",
        "        with open(\"AUC_As_PerformanceMeasure.csv\",\"w\") as file:\n",
        "          file.writelines(results)\n",
        "\n",
        "                "
      ],
      "metadata": {
        "id": "GrdWB1Zs_hbb"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_project = camel   # directory to target project\n",
        "\n",
        "perform_training(list_of_projects, target_project)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D6_lv6EAhKl",
        "outputId": "cb5ad5ed-4e38-4cb5-adb4-bb3285236d73"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1066, 26)\n",
            "(1066,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 1 1 ... 0 0 0]\n",
            "AUC 0.5652542372881356\n",
            "[0 0 0 ... 0 0 0]\n",
            "AUC 0.5313559322033898\n",
            "[0 0 0 ... 0 0 0]\n",
            "AUC 0.5093220338983051\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.538135593220339\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.5389830508474577\n",
            "(477, 26)\n",
            "(477,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 0 1 ... 0 0 0]\n",
            "AUC 0.5398305084745763\n",
            "[0 0 0 ... 0 0 0]\n",
            "AUC 0.5122881355932203\n",
            "[0 0 0 ... 0 0 0]\n",
            "AUC 0.5046610169491526\n",
            "[0 0 0 ... 0 0 0]\n",
            "AUC 0.511864406779661\n",
            "[0 0 0 ... 0 0 0]\n",
            "AUC 0.5478813559322034\n",
            "(1079, 26)\n",
            "(1079,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 1 1 ... 0 0 0]\n",
            "AUC 0.5420203735144312\n",
            "[0 0 0 ... 1 0 0]\n",
            "AUC 0.4363327674023769\n",
            "[0 0 0 ... 0 0 0]\n",
            "AUC 0.5008488964346349\n",
            "[0 0 0 ... 0 0 0]\n",
            "AUC 0.5012733446519525\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.5135823429541596\n",
            "(282, 26)\n",
            "(282,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[1 1 1 ... 1 0 1]\n",
            "AUC 0.5983050847457627\n",
            "[1 1 1 ... 0 0 1]\n",
            "AUC 0.627542372881356\n",
            "[1 1 1 ... 1 0 1]\n",
            "AUC 0.560593220338983\n",
            "[1 1 1 ... 1 0 1]\n",
            "AUC 0.4567796610169491\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 0.6906779661016949\n",
            "(483, 26)\n",
            "(483,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 1 1 ... 0 0 0]\n",
            "AUC 0.598728813559322\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 0.6775423728813559\n",
            "[1 1 0 ... 0 0 0]\n",
            "AUC 0.6648305084745763\n",
            "[1 1 0 ... 0 0 0]\n",
            "AUC 0.6338983050847458\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.5902542372881356\n",
            "(64, 26)\n",
            "(64,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.6077184054283291\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.5725190839694656\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 0.6289228159457168\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 0.6238337574215437\n",
            "[0 0 0 ... 0 0 0]\n",
            "AUC 0.5309584393553859\n",
            "(531, 26)\n",
            "(531,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 1 1 ... 0 0 0]\n",
            "AUC 0.575\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 0.6885593220338982\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 0.6478813559322034\n",
            "[1 1 0 ... 0 0 0]\n",
            "AUC 0.6254237288135593\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.6182203389830508\n",
            "(3509, 26)\n",
            "(3509,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[1 1 0 ... 0 0 0]\n",
            "AUC 0.49363867684478374\n",
            "[1 1 0 ... 0 1 1]\n",
            "AUC 0.3795589482612383\n",
            "[0 0 0 ... 0 0 0]\n",
            "AUC 0.4872773536895675\n",
            "[0 1 0 ... 0 0 1]\n",
            "AUC 0.5042408821034775\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.5542832909245123\n",
            "(268, 26)\n",
            "(268,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 0.9389830508474577\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 0.9542372881355932\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 1.0\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 1.0\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 0.7241525423728814\n",
            "(261, 26)\n",
            "(261,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.5610687022900763\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.599236641221374\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.5619168787107718\n",
            "[0 1 0 ... 0 1 1]\n",
            "AUC 0.5144189991518235\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.6030534351145038\n",
            "(1194, 26)\n",
            "(1194,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[1 1 1 ... 0 0 1]\n",
            "AUC 0.6132315521628499\n",
            "[1 1 1 ... 1 1 1]\n",
            "AUC 0.4529262086513995\n",
            "[1 1 1 ... 0 0 1]\n",
            "AUC 0.5703986429177269\n",
            "[1 1 0 ... 0 1 1]\n",
            "AUC 0.5843935538592027\n",
            "[1 1 1 ... 0 0 0]\n",
            "AUC 0.6598812553011026\n",
            "(671, 26)\n",
            "(671,)\n",
            "(1252, 26)\n",
            "(1252,)\n",
            "Data Resampled\n",
            "['Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC', 'Naive Bayes', 'Logistic Regression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'SVC'] [GaussianNB(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), SVC()]\n",
            "[1 1 1 ... 0 0 1]\n",
            "AUC 0.6340118744698897\n",
            "[1 1 1 ... 1 1 1]\n",
            "AUC 0.6085665818490247\n",
            "[1 1 1 ... 0 0 1]\n",
            "AUC 0.6849024597116201\n",
            "[1 1 1 ... 0 1 0]\n",
            "AUC 0.6505513146734521\n",
            "[0 1 0 ... 0 0 0]\n",
            "AUC 0.5513146734520781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaWR1CROcBd1"
      },
      "outputs": [],
      "source": [
        "def perform_training(list_of_projects, target_project):\n",
        "    temp_list_projects = list_of_projects.copy()\n",
        "    datasetTarget = pd.read_excel(target_project)\n",
        "    temp_list_projects.remove(target_project)\n",
        "\n",
        "    for  source_project in temp_list_projects:\n",
        "        datasetSource = pd.read_excel(source_project)\n",
        "        #print(datasetSource)\n",
        "        #Label Encoding for class column\n",
        "        from sklearn.preprocessing import LabelEncoder\n",
        "        label_encoder = preprocessing.LabelEncoder()\n",
        "        #dataset['Class']=le_class.fit_transform(dataset['Class']\n",
        "        datasetSource['class']= label_encoder.fit_transform(datasetSource['class'])\n",
        "        datasetTarget['class'] = label_encoder.fit_transform(datasetTarget['class'])\n",
        "        ##Create independent and dependent  features\n",
        "        columnsSource = datasetSource.columns.tolist()\n",
        "        columnsTarget = datasetTarget.columns.tolist()\n",
        "        ##filter the columns to remove data we do not want\n",
        "        columnsSource = [c for c in columnsSource if c not in [\"bugs\",\"Version\"]]\n",
        "        columnsTarget = [c for c in columnsTarget if c not in [\"bugs\",\"Version\"]]\n",
        "        ##store the variable we are predicting\n",
        "        targetSource=\"bugs\"\n",
        "        targetTarget=\"bugs\"\n",
        "        # define a random state\n",
        "        state = np.random.RandomState(42)\n",
        "        XSource = datasetSource[columnsSource]\n",
        "        ySource = datasetSource[targetSource]\n",
        "        XTarget = datasetTarget[columnsTarget]\n",
        "        yTarget = datasetTarget[targetTarget]\n",
        "        #X_outliers = state.uniform(low=0, high =1, size=(X.shape[0], X.shape[1]))\n",
        "\n",
        "        #splitting into train and test without random for prop as target and ant as source\n",
        "        train_data_X = XSource\n",
        "        test_data_X = XTarget\n",
        "        train_data_y = ySource\n",
        "        test_data_y = yTarget\n",
        "        #Print the shape of X & Y\n",
        "        print(XSource.shape)\n",
        "        print(ySource.shape)\n",
        "        print(XTarget.shape)\n",
        "        print(yTarget.shape)\n",
        "        \"\"\"\n",
        "        #MinMax scaling\n",
        "        from sklearn.preprocessing import MinMaxScaler\n",
        "        ss = MinMaxScaler()\n",
        "        train_data_X = ss.fit_transform(train_data_X )\n",
        "        test_data_X  = ss.transform(test_data_X)\n",
        "        train_data_y= np.array(train_data_y)\n",
        "        \"\"\"\n",
        "        from imblearn.over_sampling import ADASYN\n",
        "        from imblearn.over_sampling import BorderlineSMOTE\n",
        "        from imblearn.combine import SMOTETomek\n",
        "\n",
        "        from numpy import where\n",
        "\n",
        "        #transform the dataset\n",
        "        #oversample = BorderlineSMOTE()\n",
        "        oversample = SMOTETomek()\n",
        "        #train_data_X, train_data_y = oversample.fit_resample(train_data_X, train_data_y)\n",
        "        #test_data_X, test_data_y = oversample.fit_resample(test_data_X, test_data_y)\n",
        "\n",
        "        # Logistic Regression\n",
        "        # define models and parameters\n",
        "        model = LogisticRegression()\n",
        "\n",
        "        from sklearn.model_selection import GridSearchCV\n",
        "        # Creating the hyperparameter grid\n",
        "        c_space = np.logspace(-5, 8, 15)\n",
        "        param_grid = {'C': c_space}\n",
        "\n",
        "        print(param_grid)\n",
        "        # Instantiating logistic regression classifier\n",
        "        logreg = LogisticRegression()\n",
        "\n",
        "        # Instantiating the GridSearchCV object\n",
        "        logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
        "\n",
        "        #logreg_cv.fit(X, y)\n",
        "        logreg_cv.fit(train_data_X, train_data_y)\n",
        "\n",
        "        # Print the tuned parameters and score\n",
        "        print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
        "        print(\"Best score is {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "        best_grid = logreg_cv.best_params_\n",
        "\n",
        "        print(best_grid)\n",
        "\n",
        "        classifier1 = LogisticRegression(**best_grid).fit(train_data_X, train_data_y)\n",
        "        #predicting for testing set\n",
        "        test_p2_lr = classifier1.predict(test_data_X)\n",
        "        #Looking at the classification report\n",
        "        print(classification_report(test_p2_lr, test_data_y))\n",
        "        # Attained prediction accuracy on the testing set\n",
        "        c = confusion_matrix(test_p2_lr, test_data_y)\n",
        "        acc = c.diagonal().sum() / c.sum()\n",
        "        print('Accuracy of LR', acc)\n",
        "        print(classification_report(test_p2_lr, test_data_y))\n",
        "\n",
        "        # print classification report\n",
        "        # print(classification_report(y_test, rf_pred))\n",
        "\n",
        "        LR_fpr = c[0, 1] / [c[1, 1] + c[1, 0]]\n",
        "        print('FPR',source_project, LR_fpr)\n",
        "\n",
        "        LR_fnr = c[1, 0] / [c[0, 1] + c[0, 0]]\n",
        "        print('FNR', LR_fnr)\n",
        "        # print probability of detection\n",
        "        PD_LR = c[0, 0] / [c[0, 0] + c[0, 1]]\n",
        "        print('Probability of Detection Of optimized Logistic Regression', PD_LR)\n",
        "\n",
        "        # print Probability of False alarm\n",
        "        PF_LR = c[1, 0] / [c[0, 1] + c[1, 1]]\n",
        "        print('Probability pf false Alarm of optimized Logistic Regression', PF_LR)\n",
        "\n",
        "        #Print Recall\n",
        "        Re_LR = metrics.recall_score(test_p2_lr, test_data_y)\n",
        "        print('Recall for LR', Re_LR)\n",
        "\n",
        "        # Print Precision\n",
        "        #Pr_LR = c[0, 0] / [c[0, 0] + c[1, 0]]\n",
        "        Pr_LR = metrics.precision_score(test_p2_lr, test_data_y, labels=[1,2], average='micro')\n",
        "        print('Precison for LR', Pr_LR)\n",
        "\n",
        "        #LR_fpr, LR_tpr, LR_threshold = roc_curve(test_p2_lr, test_data_y)\n",
        "        #auc_LR = auc(LR_fpr, LR_tpr)\n",
        "\n",
        "\n",
        "\n",
        "        #F1_LR = 2 * (Pr_LR * PD_LR) / (Pr_LR + PD_LR)\n",
        "        F1_LR= f1_score(test_p2_lr, test_data_y, average='binary')\n",
        "        print('F1 Score', F1_LR)\n",
        "\n",
        "        # Print AUC\n",
        "        auc_LR = metrics.roc_auc_score(test_p2_lr, test_data_y)\n",
        "        print('Area Under Curve for LR', auc_LR)\n",
        "\n",
        "                # pd.read_excel(file_path) reads the excel data into pandas dataframe.\n",
        "                # excl_list is the list storing both target and candidate excel sheets\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFGlr651Fe6v"
      },
      "outputs": [],
      "source": [
        "target_project = camel   # directory to target project\n",
        "\n",
        "perform_training(list_of_projects, target_project)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = (np.mean(MScore,axis=1)-np.min(MScore,axis=1))\n",
        "R1 = MatchingScore * threshold[:,np.newaxis]\n",
        "R1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvUl0_FZDo-U",
        "outputId": "b5d077de-6c54-411e-be4a-e51bf2802db3"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.22800084e+02, 1.49068677e+05, 1.82584515e+05, 5.25301536e+05,\n",
              "        1.37164145e+05, 1.64545561e+05, 1.96067229e+05, 1.59765874e+05,\n",
              "        7.41561510e+04, 9.43078210e+04, 2.99812599e+05, 2.09983807e+05,\n",
              "        1.36194531e+05],\n",
              "       [1.77223177e+05, 5.02654047e+02, 1.64972557e+05, 6.09379924e+05,\n",
              "        1.04410617e+05, 3.24734236e+05, 2.78960565e+05, 2.34339059e+05,\n",
              "        1.68461159e+05, 1.64875426e+05, 4.17145386e+05, 3.21240660e+05,\n",
              "        3.24883267e+05],\n",
              "       [1.97712855e+05, 1.50261788e+05, 4.57831880e+02, 4.74898229e+05,\n",
              "        1.71625273e+05, 3.01034171e+05, 1.46507904e+05, 1.28934929e+05,\n",
              "        1.75757646e+05, 2.32549626e+05, 2.64254282e+05, 1.82122281e+05,\n",
              "        3.04765392e+05],\n",
              "       [1.38504785e+06, 1.35148158e+06, 1.15634038e+06, 1.11478514e+03,\n",
              "        1.51386600e+06, 1.25671222e+06, 1.27113010e+06, 1.33152322e+06,\n",
              "        1.44378766e+06, 1.58105327e+06, 1.26907008e+06, 1.18809274e+06,\n",
              "        1.42096915e+06],\n",
              "       [1.56167348e+05, 9.99908306e+04, 1.80451255e+05, 6.53703728e+05,\n",
              "        4.81376293e+02, 3.21699200e+05, 2.39626205e+05, 1.87589682e+05,\n",
              "        1.12016463e+05, 1.03627487e+05, 3.75178615e+05, 2.92673508e+05,\n",
              "        2.95452958e+05],\n",
              "       [2.17084358e+05, 3.60359785e+05, 3.66764414e+05, 6.28813841e+05,\n",
              "        3.72771506e+05, 5.57798607e+02, 3.41150073e+05, 3.28117580e+05,\n",
              "        2.65075384e+05, 3.15893133e+05, 4.13432630e+05, 3.25690048e+05,\n",
              "        1.16351547e+05],\n",
              "       [2.04670300e+05, 2.44939322e+05, 1.41234210e+05, 5.03249916e+05,\n",
              "        2.19702243e+05, 2.69931100e+05, 4.41351779e+02, 5.26903398e+04,\n",
              "        1.67081033e+05, 2.50613419e+05, 1.32176457e+05, 1.00282362e+05,\n",
              "        2.51013619e+05],\n",
              "       [1.55513542e+05, 1.91864558e+05, 1.15900101e+05, 4.91560334e+05,\n",
              "        1.60377525e+05, 2.42086924e+05, 4.91321056e+04, 4.11546828e+02,\n",
              "        1.14008968e+05, 1.89086654e+05, 1.67230427e+05, 1.10978719e+05,\n",
              "        2.19018991e+05],\n",
              "       [7.08901375e+04, 1.35457889e+05, 1.55160761e+05, 5.23462843e+05,\n",
              "        9.40526120e+04, 1.92072716e+05, 1.53008647e+05, 1.11967881e+05,\n",
              "        4.04178961e+02, 8.37196758e+04, 2.58197287e+05, 1.87958989e+05,\n",
              "        1.62588937e+05],\n",
              "       [1.10501767e+05, 1.62496243e+05, 2.51632186e+05, 7.02606088e+05,\n",
              "        1.06646558e+05, 2.80555854e+05, 2.81304070e+05, 2.27613593e+05,\n",
              "        1.02614896e+05, 4.95400654e+02, 4.14171248e+05, 3.17977023e+05,\n",
              "        2.38308789e+05],\n",
              "       [4.36402301e+05, 5.10728953e+05, 3.55212485e+05, 7.00594383e+05,\n",
              "        4.79651267e+05, 4.56141455e+05, 1.84306836e+05, 2.50073837e+05,\n",
              "        3.93142676e+05, 5.14512095e+05, 6.15420867e+02, 2.15025241e+05,\n",
              "        4.35250493e+05],\n",
              "       [2.40604534e+05, 3.09609582e+05, 1.92712603e+05, 5.16312022e+05,\n",
              "        2.94545086e+05, 2.82865596e+05, 1.10076026e+05, 1.30639201e+05,\n",
              "        2.25290284e+05, 3.10951194e+05, 1.69266218e+05, 4.84454580e+02,\n",
              "        2.73992235e+05],\n",
              "       [1.72862036e+05, 3.46843195e+05, 3.57219071e+05, 6.84019521e+05,\n",
              "        3.29365922e+05, 1.11935992e+05, 3.05202034e+05, 2.85586408e+05,\n",
              "        2.15870007e+05, 2.58141900e+05, 3.79526471e+05, 3.03501057e+05,\n",
              "        5.36630087e+02]])"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "R2 = MatchingScore[0][1:]*FScores[:,0]\n",
        "R2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRoxGOnUNtDp",
        "outputId": "45a5d655-ddd6-495b-dda5-c95a0672731b"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([236.57154989, 293.64337573, 649.61305988, 235.79552201,\n",
              "       323.39237635, 288.24256494, 317.35734992, 134.44487509,\n",
              "       150.28853077, 513.63181593, 372.17235743, 242.65753167])"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Rec_Score=0.3*R1[0][1:] +0.7*R2\n",
        "Final_Rec_Score\n",
        "# Saving the Final Recommendation Score in file project wise. First value implies recommendation score of Project 2 (Camel) as a source project to Target Project Ant and so on\n",
        "np.savetxt(\"Final_Rec_Score.csv\", Final_Rec_Score)\n"
      ],
      "metadata": {
        "id": "Dq86RVlXWbdS"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Evaluation of Software Projects through Grid Search CV hyperparameter optimization of machine learning classifiers.****\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Xmf-hXS-jGr_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndpDaXzFSOCp"
      },
      "outputs": [],
      "source": [
        "# grid searching key hyperparametres for logistic regression\n",
        "#from sklearn.datasets import make_blobs\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from imblearn.combine import SMOTETomek\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SNhDo46Soo_",
        "outputId": "d1b012b7-e176-400f-eee7-6b762cf377c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgYZBdkASUI8",
        "outputId": "e8f208e2-95e5-466d-ea44-3abbf7fb6f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1079, 26)\n",
            "(1079,)\n",
            "(477, 26)\n",
            "(477,)\n"
          ]
        }
      ],
      "source": [
        "#define dataset\n",
        "#dataset = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/Dataset/CPDP/ant1.7prop05Ver85.xlsx\")\n",
        "#dataset = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/Dataset/CPDP/ivy2.0poi3.0.xlsx\")\n",
        "datasetSource = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/jedit 4.3.xlsx\")\n",
        "datasetTarget = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/Dataset/WPDP/ivy 2.0.xlsx\")\n",
        "#Label Encoding for class column\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "#dataset['Class']=le_class.fit_transform(dataset['Class']\n",
        "datasetSource['class']= label_encoder.fit_transform(datasetSource['class'])\n",
        "datasetTarget['class'] = label_encoder.fit_transform(datasetTarget['class'])\n",
        "##Create independent and dependent  features\n",
        "columnsSource = datasetSource.columns.tolist()\n",
        "columnsTarget = datasetTarget.columns.tolist()\n",
        "##filter the columns to remove data we do not want\n",
        "columnsSource = [c for c in columnsSource if c not in [\"bugs\",\"Version\"]]\n",
        "columnsTarget = [c for c in columnsTarget if c not in [\"bugs\",\"Version\"]]\n",
        "##store the variable we are predicting\n",
        "targetSource=\"bugs\"\n",
        "targetTarget=\"bugs\"\n",
        "# define a random state\n",
        "state = np.random.RandomState(42)\n",
        "XSource = datasetSource[columnsSource]\n",
        "ySource = datasetSource[targetSource]\n",
        "XTarget = datasetTarget[columnsTarget]\n",
        "yTarget = datasetTarget[targetTarget]\n",
        "#X_outliers = state.uniform(low=0, high =1, size=(X.shape[0], X.shape[1]))\n",
        "\n",
        "#splitting into train and test without random for prop as target and ant as source\n",
        "train_data_X = XSource\n",
        "test_data_X = XTarget\n",
        "train_data_y = ySource\n",
        "test_data_y = yTarget\n",
        "#Print the shape of X & Y\n",
        "print(XSource.shape)\n",
        "print(ySource.shape)\n",
        "print(XTarget.shape)\n",
        "print(yTarget.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV6ro-P7SZmc"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import BorderlineSMOTE \n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "\n",
        "#transform the dataset\n",
        "#oversample = BorderlineSMOTE()\n",
        "oversample = SMOTETomek()\n",
        "train_data_X, train_data_y = oversample.fit_resample(train_data_X, train_data_y)\n",
        "test_data_X, test_data_y = oversample.fit_resample(test_data_X, test_data_y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Support Vector Machine**"
      ],
      "metadata": {
        "id": "uC6Py1eL26h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print('hyperparameter optimization with SVM')\n",
        "# define models and parameters\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# train the model on train set\n",
        "model = SVC()\n",
        "model.fit(train_data_X, train_data_y)\n",
        " \n",
        "# print prediction results\n",
        "predictions = model.predict(test_data_X)\n",
        "print(classification_report(test_data_y, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOIJAAao05L8",
        "outputId": "a27cc738-fa14-4bdc-b2a5-1983a5f1a5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67       426\n",
            "           1       0.00      0.00      0.00       426\n",
            "\n",
            "    accuracy                           0.50       852\n",
            "   macro avg       0.25      0.50      0.33       852\n",
            "weighted avg       0.25      0.50      0.33       852\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Tuning \n",
        "from sklearn.model_selection import GridSearchCV\n",
        " \n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf']}\n",
        " \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        " \n",
        "# fitting the model for grid search\n",
        "grid.fit(train_data_X, train_data_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBGkpRa62IIv",
        "outputId": "e5088b33-fea7-4f24-c8f5-e4c80914539b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.627 total time=   0.2s\n",
            "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.624 total time=   0.2s\n",
            "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.619 total time=   0.2s\n",
            "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.607 total time=   0.2s\n",
            "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.591 total time=   0.2s\n",
            "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.620 total time=   0.2s\n",
            "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.621 total time=   0.2s\n",
            "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.619 total time=   0.2s\n",
            "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.609 total time=   0.2s\n",
            "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.591 total time=   0.2s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.737 total time=   0.2s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.685 total time=   0.2s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.706 total time=   0.2s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.741 total time=   0.2s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.734 total time=   0.2s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.854 total time=   0.2s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.819 total time=   0.2s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.819 total time=   0.2s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.828 total time=   0.2s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.864 total time=   0.2s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.906 total time=   0.1s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.859 total time=   0.1s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.875 total time=   0.1s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.896 total time=   0.1s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.915 total time=   0.1s\n",
            "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.646 total time=   0.2s\n",
            "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.659 total time=   0.3s\n",
            "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.656 total time=   0.2s\n",
            "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.656 total time=   0.3s\n",
            "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.614 total time=   0.2s\n",
            "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.732 total time=   0.3s\n",
            "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.741 total time=   0.3s\n",
            "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.748 total time=   0.3s\n",
            "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.727 total time=   0.3s\n",
            "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.689 total time=   0.3s\n",
            "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.840 total time=   0.2s\n",
            "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.814 total time=   0.2s\n",
            "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.824 total time=   0.2s\n",
            "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.814 total time=   0.2s\n",
            "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.856 total time=   0.2s\n",
            "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.925 total time=   0.1s\n",
            "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.871 total time=   0.1s\n",
            "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.882 total time=   0.1s\n",
            "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.892 total time=   0.1s\n",
            "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.927 total time=   0.1s\n",
            "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.929 total time=   0.1s\n",
            "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.913 total time=   0.1s\n",
            "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.953 total time=   0.1s\n",
            "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.941 total time=   0.1s\n",
            "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.646 total time=   0.3s\n",
            "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.659 total time=   0.2s\n",
            "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.656 total time=   0.3s\n",
            "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.656 total time=   0.2s\n",
            "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.631 total time=   0.2s\n",
            "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.739 total time=   0.3s\n",
            "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.751 total time=   0.3s\n",
            "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.753 total time=   0.3s\n",
            "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.734 total time=   0.3s\n",
            "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.692 total time=   0.2s\n",
            "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.845 total time=   0.3s\n",
            "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.821 total time=   0.3s\n",
            "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.831 total time=   0.2s\n",
            "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.814 total time=   0.3s\n",
            "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.866 total time=   0.3s\n",
            "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.927 total time=   0.1s\n",
            "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.885 total time=   0.2s\n",
            "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.899 total time=   0.1s\n",
            "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.901 total time=   0.2s\n",
            "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.939 total time=   0.2s\n",
            "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.962 total time=   0.1s\n",
            "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.946 total time=   0.1s\n",
            "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.1s\n",
            "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.969 total time=   0.1s\n",
            "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.958 total time=   0.1s\n",
            "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.646 total time=   0.3s\n",
            "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.659 total time=   0.3s\n",
            "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.656 total time=   0.3s\n",
            "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.656 total time=   0.2s\n",
            "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.631 total time=   0.2s\n",
            "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.739 total time=   0.3s\n",
            "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.751 total time=   0.3s\n",
            "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.753 total time=   0.2s\n",
            "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.734 total time=   0.3s\n",
            "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.692 total time=   0.3s\n",
            "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.845 total time=   0.3s\n",
            "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.821 total time=   0.2s\n",
            "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.831 total time=   0.2s\n",
            "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.814 total time=   0.3s\n",
            "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.866 total time=   0.3s\n",
            "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.927 total time=   0.2s\n",
            "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.885 total time=   0.1s\n",
            "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.896 total time=   0.2s\n",
            "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.901 total time=   0.2s\n",
            "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.941 total time=   0.2s\n",
            "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.972 total time=   0.1s\n",
            "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.1s\n",
            "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.953 total time=   0.1s\n",
            "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.967 total time=   0.1s\n",
            "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.969 total time=   0.1s\n",
            "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.646 total time=   0.3s\n",
            "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.659 total time=   0.3s\n",
            "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.656 total time=   0.3s\n",
            "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.656 total time=   0.2s\n",
            "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.631 total time=   0.2s\n",
            "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.739 total time=   0.3s\n",
            "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.751 total time=   0.3s\n",
            "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.753 total time=   0.3s\n",
            "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.734 total time=   0.3s\n",
            "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.692 total time=   0.3s\n",
            "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.845 total time=   0.3s\n",
            "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.821 total time=   0.2s\n",
            "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.831 total time=   0.3s\n",
            "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.814 total time=   0.3s\n",
            "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.866 total time=   0.3s\n",
            "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.927 total time=   0.2s\n",
            "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.885 total time=   0.2s\n",
            "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.896 total time=   0.1s\n",
            "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.901 total time=   0.2s\n",
            "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.941 total time=   0.2s\n",
            "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.965 total time=   0.1s\n",
            "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.948 total time=   0.1s\n",
            "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.953 total time=   0.1s\n",
            "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.967 total time=   0.1s\n",
            "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.969 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVC(),\n",
              "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         'kernel': ['rbf']},\n",
              "             verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        " \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSBqYvmi2TKt",
        "outputId": "a3d2a25f-9c32-4200-ccf3-4d72d5d39060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "SVC(C=100, gamma=0.0001)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_predictions = grid.predict(test_data_X)\n",
        " \n",
        "# print classification report\n",
        "print(classification_report(test_data_y, grid_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcMtqpMJ2jt0",
        "outputId": "e69034fe-2ccb-45dd-e012-4950793828fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.95      0.73       426\n",
            "           1       0.87      0.34      0.49       426\n",
            "\n",
            "    accuracy                           0.65       852\n",
            "   macro avg       0.73      0.65      0.61       852\n",
            "weighted avg       0.73      0.65      0.61       852\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attained predic_SVMtion accuracy on the training set\n",
        "c_SVM = confusion_matrix(test_data_y, grid_predictions)\n",
        "acc_SVM = c_SVM.diagonal().sum() / c_SVM.sum()\n",
        "print('Accuracy of SVM', acc_SVM)\n",
        "print(classification_report(test_data_y, grid_predictions))\n",
        "\n",
        "# print classification report\n",
        "\n",
        "SVM_fpr, SVM_tpr, SVM_threshold = roc_curve(test_data_y, grid_predictions)\n",
        "\n",
        "# print(classification_report(y_test, rf_pred))\n",
        "SVM_fpr = c_SVM[0, 1] / [c_SVM[1, 1] + c_SVM[1, 0]]\n",
        "print('FPR', SVM_fpr)\n",
        "\n",
        "SVM_fnr = c_SVM[1, 0] / [c_SVM[0, 1] + c_SVM[0, 0]]\n",
        "print('FNR', SVM_fnr)\n",
        "# print probability of detection\n",
        "PD_SVM = c_SVM[0, 0] / [c_SVM[0, 0] + c_SVM[0, 1]]\n",
        "print('Probability of Detection Of optimized SVM', PD_SVM)\n",
        "\n",
        "# print Probability of False alarm\n",
        "PF_SVM = c_SVM[1, 0] / [c_SVM[0, 1] + c_SVM[1, 1]]\n",
        "print('Probability pf false Alarm of optimized SVM', PF_SVM)\n",
        "\n",
        "#Print Recall\n",
        "Re_SVM = metrics.recall_score(test_data_y, grid_predictions)\n",
        "print('Recall for SVM', Re_SVM)\n",
        "\n",
        "# Print Precision\n",
        "Pr_SVM = c_SVM[0, 0] / [c_SVM[0, 0] + c_SVM[1, 0]]\n",
        "print('Precison for SVM', Pr_SVM)\n",
        "\n",
        "F1 = 2 * (Pr_SVM * PD_SVM) / (Pr_SVM + PD_SVM)\n",
        "print('F1 Score', F1)\n",
        "\n",
        "# Print AUC\n",
        "\n",
        "auc_SVM=metrics.roc_auc_score(test_data_y, grid_predictions)\n",
        "print('Area Under Curve for SVM', auc_SVM)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPDo91802mP7",
        "outputId": "d637b6e2-8cb4-4433-9f66-fbe7b486d220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of SVM 0.6467136150234741\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.95      0.73       426\n",
            "           1       0.87      0.34      0.49       426\n",
            "\n",
            "    accuracy                           0.65       852\n",
            "   macro avg       0.73      0.65      0.61       852\n",
            "weighted avg       0.73      0.65      0.61       852\n",
            "\n",
            "FPR [0.04929577]\n",
            "FNR [0.657277]\n",
            "Probability of Detection Of optimized SVM [0.95070423]\n",
            "Probability pf false Alarm of optimized SVM [1.67664671]\n",
            "Recall for SVM 0.3427230046948357\n",
            "Precison for SVM [0.59124088]\n",
            "F1 Score [0.72907291]\n",
            "Area Under Curve for SVM 0.6467136150234741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Logistic Regression**"
      ],
      "metadata": {
        "id": "Vpd1YZ8v2wJH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx9ahGSVSfBF",
        "outputId": "9eafde89-1c7d-4d0e-de91-15dfb7513700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': array([1.00000000e-05, 8.48342898e-05, 7.19685673e-04, 6.10540230e-03,\n",
            "       5.17947468e-02, 4.39397056e-01, 3.72759372e+00, 3.16227766e+01,\n",
            "       2.68269580e+02, 2.27584593e+03, 1.93069773e+04, 1.63789371e+05,\n",
            "       1.38949549e+06, 1.17876863e+07, 1.00000000e+08])}\n",
            "Tuned Logistic Regression Parameters: {'C': 1389495.494373136}\n",
            "Best score is 0.9524904722452362\n",
            "{'C': 1389495.494373136}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.63      0.72       572\n",
            "           1       0.50      0.76      0.61       280\n",
            "\n",
            "    accuracy                           0.67       852\n",
            "   macro avg       0.67      0.70      0.66       852\n",
            "weighted avg       0.73      0.67      0.68       852\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# define models and parameters\n",
        "model = LogisticRegression()\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Creating the hyperparameter grid\n",
        "c_space = np.logspace(-5, 8, 15)\n",
        "param_grid = {'C': c_space}\n",
        "\n",
        "print(param_grid)\n",
        "# Instantiating logistic regression classifier\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Instantiating the GridSearchCV object\n",
        "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
        "\n",
        "#logreg_cv.fit(X, y)\n",
        "logreg_cv.fit(train_data_X, train_data_y)\n",
        "\n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
        "print(\"Best score is {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "best_grid = logreg_cv.best_params_\n",
        "\n",
        "print(best_grid)\n",
        "\n",
        "classifier1 = LogisticRegression(**best_grid).fit(train_data_X, train_data_y)\n",
        "#predicting for testing set\n",
        "test_p2_lr = classifier1.predict(test_data_X)\n",
        "#Looking at the classification report\n",
        "print(classification_report(test_p2_lr, test_data_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiGCADjzSHlL",
        "outputId": "16e5ea51-3a64-4d7c-b831-295a796708db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of LR 0.6737089201877934\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.63      0.72       572\n",
            "           1       0.50      0.76      0.61       280\n",
            "\n",
            "    accuracy                           0.67       852\n",
            "   macro avg       0.67      0.70      0.66       852\n",
            "weighted avg       0.73      0.67      0.68       852\n",
            "\n",
            "FPR [0.75714286]\n",
            "FNR [0.11538462]\n",
            "Probability of Detection Of optimized Logistic Regression [0.62937063]\n",
            "Probability pf false Alarm of optimized Logistic Regression [0.15492958]\n",
            "Recall for LR 0.7642857142857142\n",
            "Precison for LR [0.84507042]\n",
            "F1 Score [0.72144289]\n",
            "Area Under Curve for LR 0.6968281718281717\n"
          ]
        }
      ],
      "source": [
        "# Attained prediction accuracy on the testing set\n",
        "c = confusion_matrix(test_p2_lr, test_data_y)\n",
        "acc = c.diagonal().sum() / c.sum()\n",
        "print('Accuracy of LR', acc)\n",
        "print(classification_report(test_p2_lr, test_data_y))\n",
        "\n",
        "# print classification report\n",
        "# print(classification_report(y_test, rf_pred))\n",
        "\n",
        "LR_fpr = c[0, 1] / [c[1, 1] + c[1, 0]]\n",
        "print('FPR', LR_fpr)\n",
        "\n",
        "LR_fnr = c[1, 0] / [c[0, 1] + c[0, 0]]\n",
        "print('FNR', LR_fnr)\n",
        "# print probability of detection\n",
        "PD_LR = c[0, 0] / [c[0, 0] + c[0, 1]]\n",
        "print('Probability of Detection Of optimized Logistic Regression', PD_LR)\n",
        "\n",
        "# print Probability of False alarm\n",
        "PF_LR = c[1, 0] / [c[0, 1] + c[1, 1]]\n",
        "print('Probability pf false Alarm of optimized Logistic Regression', PF_LR)\n",
        "\n",
        "#Print Recall\n",
        "Re_LR = metrics.recall_score(test_p2_lr, test_data_y)\n",
        "print('Recall for LR', Re_LR)\n",
        "\n",
        "# Print Precision\n",
        "Pr_LR = c[0, 0] / [c[0, 0] + c[1, 0]]\n",
        "print('Precison for LR', Pr_LR)\n",
        "\n",
        "#LR_fpr, LR_tpr, LR_threshold = roc_curve(test_p2_lr, test_data_y)\n",
        "#auc_LR = auc(LR_fpr, LR_tpr)\n",
        "\n",
        "\n",
        "\n",
        "F1_LR = 2 * (Pr_LR * PD_LR) / (Pr_LR + PD_LR)\n",
        "print('F1 Score', F1_LR)\n",
        "\n",
        "# Print AUC\n",
        "auc_LR = metrics.roc_auc_score(test_p2_lr, test_data_y)\n",
        "print('Area Under Curve for LR', auc_LR)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyper parameter Optimization of random forest**\\\n",
        "\n",
        "----\n",
        "\n"
      ],
      "metadata": {
        "id": "w_QSBJlq4IYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a single random forest classifier - parameters are a best guess\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "clf = RandomForestClassifier(max_depth=10, random_state=0, n_estimators = 500)\n",
        "clf.fit(train_data_X, train_data_y)\n",
        "y_pred = clf.predict(test_data_X)\n",
        "\n",
        "# Create a confusion matrix\n",
        "cnf_matrix = confusion_matrix(test_data_y, y_pred)\n",
        "\n",
        "# Create heatmap from the confusion matrix\n",
        "%matplotlib inline\n",
        "class_names=[False, True] # name  of classes\n",
        "fig, ax = plt.subplots(figsize=(7, 6))\n",
        "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"Blues\", fmt='g')\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix')\n",
        "plt.xlabel('Predicted label') \n",
        "plt.ylabel('Actual label')\n",
        "tick_marks = [0.5, 1.5]\n",
        "plt.xticks(tick_marks, class_names) \n",
        "plt.yticks(tick_marks, class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "w6gQ95Fa4SMK",
        "outputId": "39a5ab4c-9e04-4d3c-8aa6-893ad41570b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.YTick at 0x7f58a1dc90d0>,\n",
              "  <matplotlib.axis.YTick at 0x7f589ed8c450>],\n",
              " [Text(0, 0.5, 'False'), Text(0, 1.5, 'True')])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper parameter optimization\n",
        "# Define parameters\n",
        "max_depth=[2, 8, 16]\n",
        "n_estimators = [164, 228, 956]\n",
        "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators)\n",
        "\n",
        "# Build the gridsearch\n",
        "dfrst = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
        "grid = GridSearchCV(estimator=dfrst, param_grid=param_grid, cv = 10)\n",
        "grid_results = grid.fit(train_data_X, train_data_y)\n",
        "\n",
        "# Summarize the results in a readable format\n",
        "print(\"Best: {0}, using {1}\".format(grid_results.cv_results_['mean_test_score'], grid_results.best_params_))\n",
        "results_df = pd.DataFrame(grid_results.cv_results_)\n",
        "results_df"
      ],
      "metadata": {
        "id": "I_Lz2qGW5g81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the best decision forest \n",
        "best_clf = grid_results.best_estimator_\n",
        "y_pred = best_clf.predict(test_data_X)\n",
        "\n",
        "# Create a confusion matrix\n",
        "cnf_matrix = confusion_matrix(test_data_y, y_pred)\n",
        "\n",
        "# Create heatmap from the confusion matrix\n",
        "class_names=[False, True] # name  of classes\n",
        "fig, ax = plt.subplots(figsize=(7, 6))\n",
        "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"Blues\", fmt='g')\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix')\n",
        "plt.ylabel('Actual label'); plt.xlabel('Predicted label')\n",
        "plt.yticks(tick_marks, class_names); plt.xticks(tick_marks, class_names)\n",
        "tick_marks = [0.5, 1.5]"
      ],
      "metadata": {
        "id": "TIGgTWn47W2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "# print(classification_report(y_test, rf_pred))\n",
        "RF_fpr, RF_tpr, RF_threshold = roc_curve(test_data_y, y_pred)\n",
        "RF_fpr = cnf_matrix[0, 1] / [cnf_matrix[1, 1] + cnf_matrix[1, 0]]\n",
        "print('FPR', RF_fpr)\n",
        "\n",
        "RF_fnr = cnf_matrix[1, 0] / [cnf_matrix[0, 1] + cnf_matrix[0, 0]]\n",
        "print('FNR', RF_fnr)\n",
        "# print probability of detection\n",
        "PD_RF = cnf_matrix[0, 0] / [cnf_matrix[0, 0] + cnf_matrix[0, 1]]\n",
        "print('Probability of Detection Of optimized Random Forest', PD_RF)\n",
        "\n",
        "# print Probability of False alarm\n",
        "PF_RF = cnf_matrix[1, 0] / [cnf_matrix[0, 1] + cnf_matrix[1, 1]]\n",
        "print('Probability pf false Alarm of optimized Random Forest', PF_RF)\n",
        "\n",
        "#Print Recall\n",
        "Re_RF = metrics.recall_score(y_pred, test_data_y)\n",
        "print('Recall for LR', Re_RF)\n",
        "\n",
        "# Print Precision\n",
        "Pr_RF = cnf_matrix[0, 0] / [cnf_matrix[0, 0] + cnf_matrix[1, 0]]\n",
        "print('Precison for RF', Pr_RF)\n",
        "\n",
        "#auc = (RF_fpr, RF_tpr)\n",
        "\n",
        "F1_RF  = 2 * (Pr_RF * PD_RF) / (Pr_RF + PD_RF)\n",
        "print('F1 Score', F1_RF)\n",
        "\n",
        "# Print AUC\n",
        "\n",
        "auc=metrics.roc_auc_score(test_data_y, y_pred)\n",
        "print('Area Under Curve for RF', auc)\n",
        "\n"
      ],
      "metadata": {
        "id": "tBkLr2Iu9lwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **`Hyperparameter Optimization through XGB`**\n"
      ],
      "metadata": {
        "id": "x2U6PhPH-hCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "estimator = XGBClassifier(\n",
        "    objective= 'binary:logistic',\n",
        "    nthread=4,\n",
        "    seed=42\n",
        ")\n",
        "parameters = {\n",
        "    'max_depth': range (2, 10, 1),\n",
        "    'n_estimators': range(60, 220, 40),\n",
        "    'learning_rate': [0.1, 0.01, 0.05]\n",
        "}\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=estimator,\n",
        "    param_grid=parameters,\n",
        "    scoring = 'roc_auc',\n",
        "    n_jobs = 10,\n",
        "    cv = 3,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "t2pzPu3p-ssk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, we can do the training.\n",
        "\n",
        "grid_search.fit(train_data_X, train_data_y)"
      ],
      "metadata": {
        "id": "_eyGV_FnE9Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "fBuS58QcFXPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the best decision forest \n",
        "opt_params = grid_search.best_estimator_\n",
        "y_predXGB = opt_params.predict(test_data_X)\n",
        "\n",
        "# Create a confusion matrix\n",
        "cnf_XGB = confusion_matrix(test_data_y, y_predXGB)"
      ],
      "metadata": {
        "id": "GnIl-JzzFsC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attained prediction accuracy on the testing set\n",
        "cnf_xgb = confusion_matrix(test_data_y,y_predXGB)\n",
        "accnf_xgb = cnf_xgb.diagonal().sum() / cnf_xgb.sum()\n",
        "print('Accuracy of xgb', accnf_xgb)\n",
        "print(classification_report(test_data_y, y_predXGB))\n",
        "\n",
        "# print classification report\n",
        "# print(classification_report(y_test, XGB_pred))\n",
        "XGB_fpr, XGB_tpr, XGB_threshold = roc_curve(test_data_y, y_predXGB)\n",
        "XGB_fpr = cnf_xgb[0, 1] / [cnf_xgb[1, 1] + cnf_xgb[1, 0]]\n",
        "print('FPR', XGB_fpr)\n",
        "\n",
        "XGB_fnr = cnf_xgb[1, 0] / [cnf_xgb[0, 1] + cnf_xgb[0, 0]]\n",
        "print('FNR', XGB_fnr)\n",
        "# print probability of detection\n",
        "PD_XGB = cnf_xgb[0, 0] / [cnf_xgb[0, 0] + cnf_xgb[0, 1]]\n",
        "print('Probability of Detection Of optimized XGB', PD_XGB)\n",
        "\n",
        "# print Probability of False alarm\n",
        "PF_XGB = cnf_xgb[1, 0] / [cnf_xgb[0, 1] + cnf_xgb[1, 1]]\n",
        "print('Probability of false Alarm of optimized XGB', PF_XGB)\n",
        "\n",
        "#Print Recall\n",
        "Re_XGB = metrics.recall_score(test_data_y, y_predXGB)\n",
        "print('Recall for optimized XGB', Re_XGB)\n",
        "\n",
        "# Print Precision\n",
        "Pr_XGB = cnf_xgb[0, 0] / [cnf_xgb[0, 0] + cnf_xgb[1, 0]]\n",
        "print('Precison for XGB', Pr_XGB)\n",
        "\n",
        "#auc = (XGB_fpr, XGB_tpr)\n",
        "\n",
        "F1_XGB  = 2 * (Pr_XGB * PD_XGB) / (Pr_XGB + PD_XGB)\n",
        "print('F1 Score', F1_XGB)\n",
        "\n",
        "# Print AUC\n",
        "\n",
        "auc=metrics.roc_auc_score(test_data_y, y_predXGB)\n",
        "print('Area Under Curve for XGB', auc)\n"
      ],
      "metadata": {
        "id": "U2CxsbD4IAYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(train_data_X, train_data_y)\n",
        "DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)"
      ],
      "metadata": {
        "id": "qX7ygu3bKf12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree.predict(test_data_X)"
      ],
      "metadata": {
        "id": "ODh23V9-LOTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_dict = {\n",
        "              \"criterion\":['gini','entropy'],\n",
        "              \"max_depth\":range(1,10),\n",
        "              \"min_samples_split\" :range(1,10),\n",
        "              \"min_samples_leaf\":range(1,5)    \n",
        "              }"
      ],
      "metadata": {
        "id": "akbTSMmfLZbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = GridSearchCV(decision_tree,\n",
        "                    param_grid=param_dict,\n",
        "                    cv=3,\n",
        "                    verbose = 1,\n",
        "                    n_jobs = -1)\n",
        "grid.fit(train_data_X, train_data_y)"
      ],
      "metadata": {
        "id": "ZZW1TBczMSpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_params_"
      ],
      "metadata": {
        "id": "29JU6DrFNBUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_estimator_"
      ],
      "metadata": {
        "id": "ilbPQUJCNJiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_score_"
      ],
      "metadata": {
        "id": "BlUkg1naNNwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the best decision forest \n",
        "opt_paramsDT = grid.best_estimator_\n",
        "y_predDT = opt_paramsDT.predict(test_data_X)\n",
        "\n",
        "# Create a confusion matrix\n",
        "cnf_DT = confusion_matrix(test_data_y, y_predDT)"
      ],
      "metadata": {
        "id": "nJkXNcfkNgE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attained prediction accuracy on the testing set\n",
        "cnf_DT = confusion_matrix(test_data_y,y_predDT)\n",
        "accnf_DT = cnf_DT.diagonal().sum() / cnf_DT.sum()\n",
        "print('Accuracy of DT', accnf_DT)\n",
        "print(classification_report(test_data_y, y_predDT))\n",
        "\n",
        "# print classification report\n",
        "# print(classification_report(y_test, DT_pred))\n",
        "DT_fpr, DT_tpr, DT_threshold = roc_curve(test_data_y, y_predDT)\n",
        "DT_fpr = cnf_DT[0, 1] / [cnf_DT[1, 1] + cnf_DT[1, 0]]\n",
        "print('FPR', DT_fpr)\n",
        "\n",
        "DT_fnr = cnf_DT[1, 0] / [cnf_DT[0, 1] + cnf_DT[0, 0]]\n",
        "print('FNR', DT_fnr)\n",
        "# print probability of detection\n",
        "PD_DT = cnf_DT[0, 0] / [cnf_DT[0, 0] + cnf_DT[0, 1]]\n",
        "print('Probability of Detection Of optimized Random Forest', PD_DT)\n",
        "\n",
        "# print Probability of False alarm\n",
        "PF_DT = cnf_DT[1, 0] / [cnf_DT[0, 1] + cnf_DT[1, 1]]\n",
        "print('Probability pf false Alarm of optimized Random Forest', PF_DT)\n",
        "\n",
        "#Print Recall\n",
        "Re_DT = metrics.recall_score(y_predDT, test_data_y)\n",
        "print('Recall for LR', Re_DT)\n",
        "\n",
        "# Print Precision\n",
        "Pr_DT = cnf_DT[0, 0] / [cnf_DT[0, 0] + cnf_DT[1, 0]]\n",
        "print('Precison for DT', Pr_DT)\n",
        "\n",
        "#auc = (DT_fpr, DT_tpr)\n",
        "\n",
        "F1_DT  = 2 * (Pr_DT * PD_DT) / (Pr_DT + PD_DT)\n",
        "print('F1 Score', F1_DT)\n",
        "\n",
        "# Print AUC\n",
        "\n",
        "auc=metrics.roc_auc_score(test_data_y, y_predDT)\n",
        "print('Area Under Curve for DT', auc)\n"
      ],
      "metadata": {
        "id": "pU8OVDvRNv3L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}